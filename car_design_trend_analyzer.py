#!/usr/bin/env python3
"""
æ±½è½¦è®¾è®¡è¶‹åŠ¿åˆ†æå™¨
åŸºäºLiblibAIæ±½è½¦äº¤é€šæ¨¡å‹æ•°æ®ä¸ºè®¾è®¡å¸ˆæä¾›è¶‹åŠ¿æ´å¯Ÿ
"""

import json
import os
from typing import Dict, List, Any, Tuple
from collections import Counter, defaultdict
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from datetime import datetime, timedelta
import jieba
import wordcloud
from matplotlib import font_manager
import numpy as np
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

class CarDesignTrendAnalyzer:
    def __init__(self, data_file: str = 'car_models_complete/complete_car_models_data.json'):
        self.data_file = data_file
        self.models_data = []
        self.output_dir = 'trend_analysis_output'
        os.makedirs(self.output_dir, exist_ok=True)
        
        # åŠ è½½æ•°æ®
        self.load_data()
        
        # è®¾è®¡è¶‹åŠ¿åˆ†æç»“æœ
        self.trend_insights = {}
    
    def load_data(self):
        """åŠ è½½æ¨¡å‹æ•°æ®"""
        try:
            with open(self.data_file, 'r', encoding='utf-8') as f:
                self.models_data = json.load(f)
            print(f"âœ… æˆåŠŸåŠ è½½ {len(self.models_data)} ä¸ªæ±½è½¦æ¨¡å‹æ•°æ®")
        except FileNotFoundError:
            print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {self.data_file}")
            print("è¯·å…ˆè¿è¡Œ complete_car_scraper.py é‡‡é›†æ•°æ®")
            return
        except json.JSONDecodeError:
            print(f"âŒ æ•°æ®æ–‡ä»¶æ ¼å¼é”™è¯¯: {self.data_file}")
            return
    
    def analyze_vehicle_type_trends(self) -> Dict[str, Any]:
        """åˆ†æè½¦è¾†ç±»å‹è¶‹åŠ¿"""
        print("ğŸš— åˆ†æè½¦è¾†ç±»å‹è¶‹åŠ¿...")
        
        vehicle_counts = Counter()
        vehicle_stats = defaultdict(lambda: {
            'total_likes': 0,
            'total_downloads': 0,
            'total_generates': 0,
            'models': []
        })
        
        for model in self.models_data:
            car_analysis = model.get('car_analysis', {})
            vehicle_types = car_analysis.get('vehicle_types', [])
            stats = model.get('stats', {})
            
            if not vehicle_types:
                vehicle_types = ['æœªåˆ†ç±»']
            
            for vehicle_type in vehicle_types:
                vehicle_counts[vehicle_type] += 1
                vehicle_stats[vehicle_type]['total_likes'] += stats.get('likeCount', 0)
                vehicle_stats[vehicle_type]['total_downloads'] += stats.get('downloadCount', 0)
                vehicle_stats[vehicle_type]['total_generates'] += stats.get('generateCount', 0)
                vehicle_stats[vehicle_type]['models'].append({
                    'title': model.get('title', ''),
                    'uuid': model.get('uuid', ''),
                    'likes': stats.get('likeCount', 0)
                })
        
        # è®¡ç®—å¹³å‡å—æ¬¢è¿åº¦
        vehicle_popularity = {}
        for vehicle_type, stats in vehicle_stats.items():
            count = vehicle_counts[vehicle_type]
            vehicle_popularity[vehicle_type] = {
                'count': count,
                'avg_likes': stats['total_likes'] / count if count > 0 else 0,
                'avg_downloads': stats['total_downloads'] / count if count > 0 else 0,
                'avg_generates': stats['total_generates'] / count if count > 0 else 0,
                'total_engagement': stats['total_likes'] + stats['total_downloads'] + stats['total_generates'],
                'top_models': sorted(stats['models'], key=lambda x: x['likes'], reverse=True)[:3]
            }
        
        # åˆ›å»ºå¯è§†åŒ–
        self.plot_vehicle_type_trends(vehicle_counts, vehicle_popularity)
        
        return {
            'vehicle_counts': dict(vehicle_counts),
            'vehicle_popularity': vehicle_popularity,
            'trend_insights': self.generate_vehicle_insights(vehicle_counts, vehicle_popularity)
        }
    
    def analyze_design_style_trends(self) -> Dict[str, Any]:
        """åˆ†æè®¾è®¡é£æ ¼è¶‹åŠ¿"""
        print("ğŸ¨ åˆ†æè®¾è®¡é£æ ¼è¶‹åŠ¿...")
        
        style_counts = Counter()
        style_combinations = Counter()
        style_performance = defaultdict(lambda: {
            'total_likes': 0,
            'total_downloads': 0,
            'models': []
        })
        
        for model in self.models_data:
            car_analysis = model.get('car_analysis', {})
            design_styles = car_analysis.get('design_styles', [])
            stats = model.get('stats', {})
            
            if not design_styles:
                design_styles = ['é€šç”¨è®¾è®¡']
            
            # å•ä¸€é£æ ¼ç»Ÿè®¡
            for style in design_styles:
                style_counts[style] += 1
                style_performance[style]['total_likes'] += stats.get('likeCount', 0)
                style_performance[style]['total_downloads'] += stats.get('downloadCount', 0)
                style_performance[style]['models'].append({
                    'title': model.get('title', ''),
                    'uuid': model.get('uuid', ''),
                    'likes': stats.get('likeCount', 0)
                })
            
            # é£æ ¼ç»„åˆç»Ÿè®¡
            if len(design_styles) > 1:
                combo = ' + '.join(sorted(design_styles))
                style_combinations[combo] += 1
        
        # åˆ›å»ºå¯è§†åŒ–
        self.plot_design_style_trends(style_counts, style_combinations)
        
        return {
            'style_counts': dict(style_counts),
            'style_combinations': dict(style_combinations.most_common(10)),
            'style_performance': {
                style: {
                    'count': style_counts[style],
                    'avg_likes': data['total_likes'] / style_counts[style] if style_counts[style] > 0 else 0,
                    'avg_downloads': data['total_downloads'] / style_counts[style] if style_counts[style] > 0 else 0,
                    'top_models': sorted(data['models'], key=lambda x: x['likes'], reverse=True)[:3]
                }
                for style, data in style_performance.items()
            }
        }
    
    def analyze_render_style_trends(self) -> Dict[str, Any]:
        """åˆ†ææ¸²æŸ“é£æ ¼è¶‹åŠ¿"""
        print("ğŸ–¼ï¸ åˆ†ææ¸²æŸ“é£æ ¼è¶‹åŠ¿...")
        
        render_counts = Counter()
        render_quality = defaultdict(lambda: {
            'total_likes': 0,
            'total_generates': 0,
            'models': []
        })
        
        for model in self.models_data:
            car_analysis = model.get('car_analysis', {})
            render_styles = car_analysis.get('render_styles', [])
            stats = model.get('stats', {})
            
            if not render_styles:
                render_styles = ['é€šç”¨æ¸²æŸ“']
            
            for render_style in render_styles:
                render_counts[render_style] += 1
                render_quality[render_style]['total_likes'] += stats.get('likeCount', 0)
                render_quality[render_style]['total_generates'] += stats.get('generateCount', 0)
                render_quality[render_style]['models'].append({
                    'title': model.get('title', ''),
                    'uuid': model.get('uuid', ''),
                    'likes': stats.get('likeCount', 0),
                    'generates': stats.get('generateCount', 0)
                })
        
        return {
            'render_counts': dict(render_counts),
            'render_quality': {
                style: {
                    'count': render_counts[style],
                    'avg_likes': data['total_likes'] / render_counts[style] if render_counts[style] > 0 else 0,
                    'avg_generates': data['total_generates'] / render_counts[style] if render_counts[style] > 0 else 0,
                    'engagement_ratio': (data['total_likes'] + data['total_generates']) / render_counts[style] if render_counts[style] > 0 else 0,
                    'top_models': sorted(data['models'], key=lambda x: x['likes'], reverse=True)[:3]
                }
                for style, data in render_quality.items()
            }
        }
    
    def analyze_author_trends(self) -> Dict[str, Any]:
        """åˆ†æä½œè€…å’Œåˆ›ä½œè¶‹åŠ¿"""
        print("ğŸ‘¥ åˆ†æä½œè€…åˆ›ä½œè¶‹åŠ¿...")
        
        author_stats = defaultdict(lambda: {
            'model_count': 0,
            'total_likes': 0,
            'total_downloads': 0,
            'total_generates': 0,
            'specialties': Counter(),
            'models': []
        })
        
        for model in self.models_data:
            author = model.get('author', {})
            username = author.get('username', 'æœªçŸ¥ä½œè€…')
            stats = model.get('stats', {})
            car_analysis = model.get('car_analysis', {})
            
            author_stats[username]['model_count'] += 1
            author_stats[username]['total_likes'] += stats.get('likeCount', 0)
            author_stats[username]['total_downloads'] += stats.get('downloadCount', 0)
            author_stats[username]['total_generates'] += stats.get('generateCount', 0)
            
            # ç»Ÿè®¡ä¸“é•¿
            for vehicle_type in car_analysis.get('vehicle_types', []):
                author_stats[username]['specialties'][vehicle_type] += 1
            
            author_stats[username]['models'].append({
                'title': model.get('title', ''),
                'uuid': model.get('uuid', ''),
                'likes': stats.get('likeCount', 0)
            })
        
        # è®¡ç®—ä½œè€…æ’å
        top_authors = []
        for username, data in author_stats.items():
            if data['model_count'] >= 2:  # è‡³å°‘2ä¸ªæ¨¡å‹æ‰è€ƒè™‘
                engagement_score = (
                    data['total_likes'] * 1.0 + 
                    data['total_downloads'] * 2.0 + 
                    data['total_generates'] * 0.5
                )
                top_authors.append({
                    'username': username,
                    'model_count': data['model_count'],
                    'avg_likes': data['total_likes'] / data['model_count'],
                    'engagement_score': engagement_score,
                    'main_specialty': data['specialties'].most_common(1)[0] if data['specialties'] else ('é€šç”¨', 0),
                    'top_model': max(data['models'], key=lambda x: x['likes'])
                })
        
        top_authors.sort(key=lambda x: x['engagement_score'], reverse=True)
        
        return {
            'total_authors': len(author_stats),
            'active_authors': len([a for a in author_stats.values() if a['model_count'] >= 2]),
            'top_authors': top_authors[:15],
            'author_specialties': {
                username: dict(data['specialties'].most_common(3))
                for username, data in author_stats.items() 
                if data['model_count'] >= 3
            }
        }
    
    def analyze_keyword_trends(self) -> Dict[str, Any]:
        """åˆ†æå…³é”®è¯å’Œæ ‡ç­¾è¶‹åŠ¿"""
        print("ğŸ” åˆ†æå…³é”®è¯è¶‹åŠ¿...")
        
        all_keywords = []
        all_tags = []
        keyword_performance = defaultdict(lambda: {
            'count': 0,
            'total_likes': 0,
            'models': []
        })
        
        for model in self.models_data:
            keywords = model.get('keywords', [])
            tags = model.get('tags', [])
            stats = model.get('stats', {})
            
            all_keywords.extend(keywords)
            all_tags.extend(tags)
            
            for keyword in keywords:
                keyword_performance[keyword]['count'] += 1
                keyword_performance[keyword]['total_likes'] += stats.get('likeCount', 0)
                keyword_performance[keyword]['models'].append({
                    'title': model.get('title', ''),
                    'likes': stats.get('likeCount', 0)
                })
        
        # ç­›é€‰é«˜é¢‘å…³é”®è¯
        keyword_counts = Counter(all_keywords)
        tag_counts = Counter(all_tags)
        
        # çƒ­é—¨å…³é”®è¯ï¼ˆå‡ºç°é¢‘ç‡ >= 3ï¼‰
        hot_keywords = {
            keyword: {
                'count': keyword_performance[keyword]['count'],
                'avg_likes': keyword_performance[keyword]['total_likes'] / keyword_performance[keyword]['count'],
                'top_model': max(keyword_performance[keyword]['models'], key=lambda x: x['likes'])
            }
            for keyword, count in keyword_counts.items() 
            if count >= 3
        }
        
        # ç”Ÿæˆè¯äº‘
        self.generate_keyword_wordcloud(keyword_counts)
        
        return {
            'top_keywords': dict(keyword_counts.most_common(30)),
            'top_tags': dict(tag_counts.most_common(20)),
            'hot_keywords': hot_keywords,
            'keyword_insights': self.generate_keyword_insights(keyword_counts, hot_keywords)
        }
    
    def analyze_temporal_trends(self) -> Dict[str, Any]:
        """åˆ†ææ—¶é—´è¶‹åŠ¿ï¼ˆåŸºäºæ¨¡å‹å—æ¬¢è¿ç¨‹åº¦æ¨æ–­ï¼‰"""
        print("ğŸ“… åˆ†ææ—¶é—´è¶‹åŠ¿...")
        
        # æ ¹æ®ç‚¹èµæ•°å’Œç”Ÿæˆæ•°æ¨æ–­æµè¡Œåº¦æ—¶é—´çº¿
        models_by_popularity = sorted(
            self.models_data, 
            key=lambda x: x.get('stats', {}).get('likeCount', 0) + x.get('stats', {}).get('generateCount', 0),
            reverse=True
        )
        
        # å°†æ¨¡å‹åˆ†ä¸ºä¸åŒæ—¶æœŸï¼ˆåŸºäºå—æ¬¢è¿ç¨‹åº¦ï¼‰
        total_models = len(models_by_popularity)
        recent_models = models_by_popularity[:total_models//3]  # æœ€è¿‘æµè¡Œ
        stable_models = models_by_popularity[total_models//3:2*total_models//3]  # ç¨³å®šæœŸ
        emerging_models = models_by_popularity[2*total_models//3:]  # æ–°å…´
        
        periods = {
            'çƒ­é—¨æµè¡ŒæœŸ': recent_models,
            'ç¨³å®šå‘å±•æœŸ': stable_models,
            'æ–°å…´æ¢ç´¢æœŸ': emerging_models
        }
        
        period_analysis = {}
        for period_name, models in periods.items():
            if not models:
                continue
                
            vehicle_types = Counter()
            design_styles = Counter()
            render_styles = Counter()
            
            for model in models:
                car_analysis = model.get('car_analysis', {})
                vehicle_types.update(car_analysis.get('vehicle_types', []))
                design_styles.update(car_analysis.get('design_styles', []))
                render_styles.update(car_analysis.get('render_styles', []))
            
            period_analysis[period_name] = {
                'model_count': len(models),
                'top_vehicle_types': dict(vehicle_types.most_common(5)),
                'top_design_styles': dict(design_styles.most_common(5)),
                'top_render_styles': dict(render_styles.most_common(5)),
                'avg_likes': sum(m.get('stats', {}).get('likeCount', 0) for m in models) / len(models),
                'representative_models': [
                    {
                        'title': m.get('title', ''),
                        'uuid': m.get('uuid', ''),
                        'likes': m.get('stats', {}).get('likeCount', 0),
                        'author': m.get('author', {}).get('username', '')
                    }
                    for m in models[:5]
                ]
            }
        
        return period_analysis
    
    def generate_vehicle_insights(self, vehicle_counts: Counter, vehicle_popularity: Dict) -> List[str]:
        """ç”Ÿæˆè½¦è¾†ç±»å‹æ´å¯Ÿ"""
        insights = []
        
        # æœ€å—æ¬¢è¿çš„è½¦å‹
        most_popular = max(vehicle_counts, key=vehicle_counts.get)
        insights.append(f"ğŸ† {most_popular} æ˜¯æœ€å—å…³æ³¨çš„è½¦è¾†ç±»å‹ï¼Œå…±æœ‰ {vehicle_counts[most_popular]} ä¸ªç›¸å…³æ¨¡å‹")
        
        # æœ€é«˜äº’åŠ¨ç‡è½¦å‹
        if vehicle_popularity:
            best_engagement = max(
                vehicle_popularity.items(), 
                key=lambda x: x[1]['total_engagement']
            )
            insights.append(f"ğŸ’– {best_engagement[0]} å…·æœ‰æœ€é«˜çš„ç”¨æˆ·äº’åŠ¨ç‡ï¼Œå¹³å‡æ¯ä¸ªæ¨¡å‹è·å¾— {best_engagement[1]['avg_likes']:.1f} ä¸ªç‚¹èµ")
        
        # æ–°å…´è¶‹åŠ¿
        emerging_types = [vtype for vtype, count in vehicle_counts.items() if count >= 2 and count <= 5]
        if emerging_types:
            insights.append(f"ğŸŒŸ æ–°å…´è½¦å‹è¶‹åŠ¿ï¼š{', '.join(emerging_types[:3])} æ­£åœ¨è·å¾—è®¾è®¡å¸ˆå…³æ³¨")
        
        return insights
    
    def generate_keyword_insights(self, keyword_counts: Counter, hot_keywords: Dict) -> List[str]:
        """ç”Ÿæˆå…³é”®è¯æ´å¯Ÿ"""
        insights = []
        
        # æœ€çƒ­é—¨å…³é”®è¯
        top_keyword = keyword_counts.most_common(1)[0] if keyword_counts else None
        if top_keyword:
            insights.append(f"ğŸ”¥ '{top_keyword[0]}' æ˜¯æœ€çƒ­é—¨çš„è®¾è®¡å…³é”®è¯ï¼Œå‡ºç°åœ¨ {top_keyword[1]} ä¸ªæ¨¡å‹ä¸­")
        
        # é«˜è´¨é‡å…³é”®è¯
        quality_keywords = [
            (keyword, data['avg_likes']) 
            for keyword, data in hot_keywords.items() 
            if data['avg_likes'] > 50
        ]
        if quality_keywords:
            best_quality = max(quality_keywords, key=lambda x: x[1])
            insights.append(f"â­ '{best_quality[0]}' ç›¸å…³æ¨¡å‹è´¨é‡æœ€é«˜ï¼Œå¹³å‡è·å¾— {best_quality[1]:.1f} ä¸ªç‚¹èµ")
        
        # è®¾è®¡æ–¹å‘å»ºè®®
        tech_keywords = [k for k in keyword_counts.keys() if any(tech in k.lower() for tech in ['3d', 'render', 'ai', 'æ¸²æŸ“', 'å»ºæ¨¡'])]
        if tech_keywords:
            insights.append(f"ğŸ”§ æŠ€æœ¯å¯¼å‘å…³é”®è¯è¶‹åŠ¿ï¼š{', '.join(tech_keywords[:3])} è¡¨æ˜è®¾è®¡å¸ˆå…³æ³¨æŠ€æœ¯å®ç°")
        
        return insights
    
    def plot_vehicle_type_trends(self, vehicle_counts: Counter, vehicle_popularity: Dict):
        """ç»˜åˆ¶è½¦è¾†ç±»å‹è¶‹åŠ¿å›¾"""
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle('æ±½è½¦ç±»å‹è®¾è®¡è¶‹åŠ¿åˆ†æ', fontsize=16, fontweight='bold')
        
        # 1. è½¦å‹æ•°é‡åˆ†å¸ƒ
        types = list(vehicle_counts.keys())
        counts = list(vehicle_counts.values())
        
        ax1.bar(types, counts, color=sns.color_palette("husl", len(types)))
        ax1.set_title('å„è½¦å‹æ¨¡å‹æ•°é‡åˆ†å¸ƒ')
        ax1.set_xlabel('è½¦è¾†ç±»å‹')
        ax1.set_ylabel('æ¨¡å‹æ•°é‡')
        ax1.tick_params(axis='x', rotation=45)
        
        # 2. è½¦å‹å¹³å‡å—æ¬¢è¿åº¦
        if vehicle_popularity:
            pop_types = list(vehicle_popularity.keys())
            avg_likes = [vehicle_popularity[t]['avg_likes'] for t in pop_types]
            
            ax2.barh(pop_types, avg_likes, color=sns.color_palette("viridis", len(pop_types)))
            ax2.set_title('è½¦å‹å¹³å‡å—æ¬¢è¿åº¦ï¼ˆç‚¹èµæ•°ï¼‰')
            ax2.set_xlabel('å¹³å‡ç‚¹èµæ•°')
        
        # 3. è½¦å‹æ€»äº’åŠ¨é‡
        if vehicle_popularity:
            total_engagement = [vehicle_popularity[t]['total_engagement'] for t in pop_types]
            
            ax3.pie(total_engagement, labels=pop_types, autopct='%1.1f%%', startangle=90)
            ax3.set_title('è½¦å‹æ€»äº’åŠ¨é‡åˆ†å¸ƒ')
        
        # 4. è½¦å‹è´¨é‡ vs æ•°é‡æ•£ç‚¹å›¾
        if vehicle_popularity:
            x_data = [vehicle_popularity[t]['count'] for t in pop_types]
            y_data = [vehicle_popularity[t]['avg_likes'] for t in pop_types]
            
            scatter = ax4.scatter(x_data, y_data, s=100, alpha=0.7, c=range(len(pop_types)), cmap='tab10')
            ax4.set_xlabel('æ¨¡å‹æ•°é‡')
            ax4.set_ylabel('å¹³å‡ç‚¹èµæ•°')
            ax4.set_title('è½¦å‹æ•°é‡ vs è´¨é‡åˆ†æ')
            
            # æ·»åŠ æ ‡ç­¾
            for i, txt in enumerate(pop_types):
                ax4.annotate(txt, (x_data[i], y_data[i]), xytext=(5, 5), textcoords='offset points', fontsize=8)
        
        plt.tight_layout()
        plt.savefig(os.path.join(self.output_dir, 'vehicle_type_trends.png'), dpi=300, bbox_inches='tight')
        plt.close()
    
    def plot_design_style_trends(self, style_counts: Counter, style_combinations: Counter):
        """ç»˜åˆ¶è®¾è®¡é£æ ¼è¶‹åŠ¿å›¾"""
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))
        fig.suptitle('è®¾è®¡é£æ ¼è¶‹åŠ¿åˆ†æ', fontsize=16, fontweight='bold')
        
        # 1. è®¾è®¡é£æ ¼åˆ†å¸ƒ
        styles = list(style_counts.keys())
        counts = list(style_counts.values())
        
        ax1.pie(counts, labels=styles, autopct='%1.1f%%', startangle=90)
        ax1.set_title('è®¾è®¡é£æ ¼åˆ†å¸ƒ')
        
        # 2. çƒ­é—¨é£æ ¼ç»„åˆ
        if style_combinations:
            combo_names = list(style_combinations.keys())[:8]  # å‰8ä¸ªç»„åˆ
            combo_counts = list(style_combinations.values())[:8]
            
            ax2.barh(combo_names, combo_counts, color=sns.color_palette("Set3", len(combo_names)))
            ax2.set_title('çƒ­é—¨é£æ ¼ç»„åˆ')
            ax2.set_xlabel('å‡ºç°æ¬¡æ•°')
            
            # è°ƒæ•´æ ‡ç­¾æ˜¾ç¤º
            ax2.tick_params(axis='y', labelsize=8)
        
        plt.tight_layout()
        plt.savefig(os.path.join(self.output_dir, 'design_style_trends.png'), dpi=300, bbox_inches='tight')
        plt.close()
    
    def generate_keyword_wordcloud(self, keyword_counts: Counter):
        """ç”Ÿæˆå…³é”®è¯è¯äº‘"""
        if not keyword_counts:
            return
        
        # è¿‡æ»¤æ‰è¿‡çŸ­çš„è¯
        filtered_keywords = {k: v for k, v in keyword_counts.items() if len(k) >= 2}
        
        if not filtered_keywords:
            return
        
        try:
            # ç”Ÿæˆè¯äº‘
            wc = wordcloud.WordCloud(
                width=1200, 
                height=600,
                background_color='white',
                font_path='SimHei.ttf',  # å°è¯•ä½¿ç”¨ä¸­æ–‡å­—ä½“
                max_words=100,
                relative_scaling=0.5,
                colormap='viridis'
            ).generate_from_frequencies(filtered_keywords)
            
            plt.figure(figsize=(12, 6))
            plt.imshow(wc, interpolation='bilinear')
            plt.axis('off')
            plt.title('æ±½è½¦è®¾è®¡å…³é”®è¯äº‘å›¾', fontsize=16, pad=20)
            plt.tight_layout()
            plt.savefig(os.path.join(self.output_dir, 'keyword_wordcloud.png'), dpi=300, bbox_inches='tight')
            plt.close()
            
        except Exception as e:
            print(f"âš ï¸ è¯äº‘ç”Ÿæˆå¤±è´¥: {e}")
    
    def generate_comprehensive_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆç»¼åˆè¶‹åŠ¿æŠ¥å‘Š"""
        print("ğŸ“Š ç”Ÿæˆç»¼åˆè¶‹åŠ¿æŠ¥å‘Š...")
        
        # æ‰§è¡Œæ‰€æœ‰åˆ†æ
        vehicle_trends = self.analyze_vehicle_type_trends()
        design_trends = self.analyze_design_style_trends()
        render_trends = self.analyze_render_style_trends()
        author_trends = self.analyze_author_trends()
        keyword_trends = self.analyze_keyword_trends()
        temporal_trends = self.analyze_temporal_trends()
        
        # ç”Ÿæˆç»¼åˆæ´å¯Ÿ
        comprehensive_insights = {
            'report_metadata': {
                'generated_at': datetime.now().isoformat(),
                'total_models_analyzed': len(self.models_data),
                'analysis_scope': 'æ±½è½¦äº¤é€šè®¾è®¡è¶‹åŠ¿'
            },
            
            'executive_summary': {
                'key_findings': [
                    f"å…±åˆ†æäº† {len(self.models_data)} ä¸ªæ±½è½¦äº¤é€šç›¸å…³AIæ¨¡å‹",
                    f"å‘ç° {len(vehicle_trends['vehicle_counts'])} ç§ä¸»è¦è½¦è¾†ç±»å‹è®¾è®¡æ–¹å‘",
                    f"è¯†åˆ«å‡º {len(design_trends['style_counts'])} ç§è®¾è®¡é£æ ¼è¶‹åŠ¿",
                    f"ç»Ÿè®¡äº† {author_trends['total_authors']} ä½æ´»è·ƒè®¾è®¡å¸ˆçš„åˆ›ä½œåå¥½"
                ],
                'trending_vehicles': list(vehicle_trends['vehicle_counts'].keys())[:5],
                'popular_styles': list(design_trends['style_counts'].keys())[:5],
                'top_creators': [author['username'] for author in author_trends['top_authors'][:5]]
            },
            
            'detailed_analysis': {
                'vehicle_type_trends': vehicle_trends,
                'design_style_trends': design_trends,
                'render_style_trends': render_trends,
                'author_trends': author_trends,
                'keyword_trends': keyword_trends,
                'temporal_trends': temporal_trends
            },
            
            'design_recommendations': self.generate_design_recommendations(
                vehicle_trends, design_trends, render_trends, keyword_trends
            ),
            
            'market_opportunities': self.identify_market_opportunities(
                vehicle_trends, design_trends, author_trends
            )
        }
        
        return comprehensive_insights
    
    def generate_design_recommendations(self, vehicle_trends, design_trends, render_trends, keyword_trends) -> List[Dict[str, str]]:
        """ç”Ÿæˆè®¾è®¡å»ºè®®"""
        recommendations = []
        
        # åŸºäºè½¦å‹è¶‹åŠ¿çš„å»ºè®®
        top_vehicle = max(vehicle_trends['vehicle_counts'], key=vehicle_trends['vehicle_counts'].get)
        recommendations.append({
            'category': 'è½¦å‹é€‰æ‹©',
            'recommendation': f"é‡ç‚¹å…³æ³¨ {top_vehicle} è®¾è®¡ï¼Œè¿™æ˜¯å½“å‰æœ€å—æ¬¢è¿çš„è½¦å‹ç±»åˆ«",
            'reason': f"è¯¥ç±»å‹å·²æœ‰ {vehicle_trends['vehicle_counts'][top_vehicle]} ä¸ªæ¨¡å‹ï¼Œæ˜¾ç¤ºå‡ºå¼ºçƒˆçš„å¸‚åœºéœ€æ±‚"
        })
        
        # åŸºäºè®¾è®¡é£æ ¼çš„å»ºè®®
        if design_trends['style_combinations']:
            top_combo = list(design_trends['style_combinations'].keys())[0]
            recommendations.append({
                'category': 'é£æ ¼èåˆ',
                'recommendation': f"å°è¯• {top_combo} çš„è®¾è®¡ç»„åˆ",
                'reason': "è¿™ç§é£æ ¼ç»„åˆå·²è¢«å¤šä½è®¾è®¡å¸ˆéªŒè¯ï¼Œå…·æœ‰è‰¯å¥½çš„ç”¨æˆ·æ¥å—åº¦"
            })
        
        # åŸºäºæ¸²æŸ“é£æ ¼çš„å»ºè®®
        best_render = max(
            render_trends['render_quality'].items(),
            key=lambda x: x[1]['engagement_ratio']
        )[0]
        recommendations.append({
            'category': 'æ¸²æŸ“æŠ€æœ¯',
            'recommendation': f"é‡‡ç”¨ {best_render} æ¸²æŸ“é£æ ¼",
            'reason': f"è¯¥é£æ ¼å…·æœ‰æœ€é«˜çš„ç”¨æˆ·äº’åŠ¨ç‡ï¼Œå¹³å‡æ¯ä¸ªæ¨¡å‹è·å¾— {render_trends['render_quality'][best_render]['avg_likes']:.1f} ä¸ªç‚¹èµ"
        })
        
        # åŸºäºå…³é”®è¯çš„å»ºè®®
        hot_keywords = list(keyword_trends['top_keywords'].keys())[:3]
        recommendations.append({
            'category': 'å…³é”®è¯ä¼˜åŒ–',
            'recommendation': f"åœ¨ä½œå“æ ‡é¢˜å’Œæè¿°ä¸­åŒ…å«: {', '.join(hot_keywords)}",
            'reason': "è¿™äº›æ˜¯å½“å‰æœ€çƒ­é—¨çš„è®¾è®¡å…³é”®è¯ï¼Œæœ‰åŠ©äºæé«˜ä½œå“æ›å…‰åº¦"
        })
        
        return recommendations
    
    def identify_market_opportunities(self, vehicle_trends, design_trends, author_trends) -> List[Dict[str, str]]:
        """è¯†åˆ«å¸‚åœºæœºä¼š"""
        opportunities = []
        
        # ä½ç«äº‰ä½†æœ‰æ½œåŠ›çš„è½¦å‹
        vehicle_counts = vehicle_trends['vehicle_counts']
        underrepresented_vehicles = [
            vtype for vtype, count in vehicle_counts.items() 
            if 2 <= count <= 5
        ]
        
        if underrepresented_vehicles:
            opportunities.append({
                'type': 'è“æµ·è½¦å‹',
                'opportunity': f"å…³æ³¨ {', '.join(underrepresented_vehicles[:3])} ç­‰è½¦å‹è®¾è®¡",
                'potential': "è¿™äº›è½¦å‹ç«äº‰è¾ƒå°‘ä½†æœ‰å¢é•¿æ½œåŠ›ï¼Œé€‚åˆå¼€æ‹“æ€§è®¾è®¡å¸ˆ"
            })
        
        # é«˜è´¨é‡ä½œè€…è¾ƒå°‘æ¶‰åŠçš„é¢†åŸŸ
        author_specialties = author_trends.get('author_specialties', {})
        all_specialties = Counter()
        for specialties in author_specialties.values():
            all_specialties.update(specialties.keys())
        
        rare_specialties = [
            specialty for specialty, count in all_specialties.items() 
            if count <= 2
        ]
        
        if rare_specialties:
            opportunities.append({
                'type': 'ä¸“ä¸šåŒ–æœºä¼š',
                'opportunity': f"ä¸“æ³¨äº {', '.join(rare_specialties[:3])} é¢†åŸŸ",
                'potential': "è¿™äº›é¢†åŸŸç¼ºä¹ä¸“ä¸šè®¾è®¡å¸ˆï¼Œæœ‰æœºä¼šå»ºç«‹ä¸“ä¸šå£°èª‰"
            })
        
        # é£æ ¼åˆ›æ–°æœºä¼š
        style_counts = design_trends['style_counts']
        innovative_styles = [
            style for style, count in style_counts.items() 
            if count >= 3 and count <= 8
        ]
        
        if innovative_styles:
            opportunities.append({
                'type': 'é£æ ¼åˆ›æ–°',
                'opportunity': f"æ·±åŒ– {', '.join(innovative_styles[:2])} é£æ ¼",
                'potential': "è¿™äº›é£æ ¼æœ‰åŸºç¡€ä½†æœªé¥±å’Œï¼Œé€‚åˆæ·±å…¥å‘å±•"
            })
        
        return opportunities
    
    def save_report(self, report: Dict[str, Any]):
        """ä¿å­˜åˆ†ææŠ¥å‘Š"""
        # ä¿å­˜JSONæ ¼å¼æŠ¥å‘Š
        report_file = os.path.join(self.output_dir, 'car_design_trend_report.json')
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        # ä¿å­˜Markdownæ ¼å¼æŠ¥å‘Š
        self.generate_markdown_report(report)
        
        print(f"âœ… è¶‹åŠ¿åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ° {self.output_dir}/")
    
    def generate_markdown_report(self, report: Dict[str, Any]):
        """ç”ŸæˆMarkdownæ ¼å¼æŠ¥å‘Š"""
        md_content = f"""# æ±½è½¦è®¾è®¡è¶‹åŠ¿æ´å¯ŸæŠ¥å‘Š

## ğŸ“Š æ‰§è¡Œæ‘˜è¦

**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: {report['report_metadata']['generated_at']}  
**åˆ†æèŒƒå›´**: {report['report_metadata']['analysis_scope']}  
**æ¨¡å‹æ€»æ•°**: {report['report_metadata']['total_models_analyzed']}

### ğŸ¯ æ ¸å¿ƒå‘ç°

{chr(10).join(f"- {finding}" for finding in report['executive_summary']['key_findings'])}

### ğŸš— çƒ­é—¨è½¦å‹è¶‹åŠ¿
{', '.join(report['executive_summary']['trending_vehicles'])}

### ğŸ¨ æµè¡Œè®¾è®¡é£æ ¼  
{', '.join(report['executive_summary']['popular_styles'])}

### ğŸ‘‘ é¡¶çº§è®¾è®¡å¸ˆ
{', '.join(report['executive_summary']['top_creators'])}

## ğŸ“ˆ è¯¦ç»†åˆ†æ

### è½¦è¾†ç±»å‹è¶‹åŠ¿
{self._format_vehicle_trends(report['detailed_analysis']['vehicle_type_trends'])}

### è®¾è®¡é£æ ¼åˆ†æ
{self._format_design_trends(report['detailed_analysis']['design_style_trends'])}

### ä½œè€…åˆ›ä½œè¶‹åŠ¿
{self._format_author_trends(report['detailed_analysis']['author_trends'])}

## ğŸ’¡ è®¾è®¡å»ºè®®

{self._format_recommendations(report['design_recommendations'])}

## ğŸš€ å¸‚åœºæœºä¼š

{self._format_opportunities(report['market_opportunities'])}

## ğŸ“ é™„ä»¶è¯´æ˜

- `vehicle_type_trends.png`: è½¦è¾†ç±»å‹è¶‹åŠ¿å¯è§†åŒ–
- `design_style_trends.png`: è®¾è®¡é£æ ¼è¶‹åŠ¿å›¾è¡¨  
- `keyword_wordcloud.png`: å…³é”®è¯è¯äº‘å›¾
- `car_design_trend_report.json`: å®Œæ•´æ•°æ®æŠ¥å‘Š

---
*æœ¬æŠ¥å‘Šç”±LiblibAIæ±½è½¦è®¾è®¡è¶‹åŠ¿åˆ†æå™¨è‡ªåŠ¨ç”Ÿæˆ*
"""
        
        md_file = os.path.join(self.output_dir, 'trend_report.md')
        with open(md_file, 'w', encoding='utf-8') as f:
            f.write(md_content)
    
    def _format_vehicle_trends(self, trends: Dict) -> str:
        """æ ¼å¼åŒ–è½¦è¾†è¶‹åŠ¿"""
        lines = []
        for vehicle, count in list(trends['vehicle_counts'].items())[:5]:
            lines.append(f"- **{vehicle}**: {count} ä¸ªæ¨¡å‹")
        return '\n'.join(lines)
    
    def _format_design_trends(self, trends: Dict) -> str:
        """æ ¼å¼åŒ–è®¾è®¡è¶‹åŠ¿"""
        lines = []
        for style, count in list(trends['style_counts'].items())[:5]:
            lines.append(f"- **{style}**: {count} ä¸ªæ¨¡å‹")
        return '\n'.join(lines)
    
    def _format_author_trends(self, trends: Dict) -> str:
        """æ ¼å¼åŒ–ä½œè€…è¶‹åŠ¿"""
        lines = []
        for author in trends['top_authors'][:5]:
            lines.append(f"- **{author['username']}**: {author['model_count']} ä¸ªæ¨¡å‹ï¼Œå¹³å‡ {author['avg_likes']:.1f} ç‚¹èµ")
        return '\n'.join(lines)
    
    def _format_recommendations(self, recommendations: List) -> str:
        """æ ¼å¼åŒ–å»ºè®®"""
        lines = []
        for rec in recommendations:
            lines.append(f"### {rec['category']}")
            lines.append(f"**å»ºè®®**: {rec['recommendation']}")
            lines.append(f"**ç†ç”±**: {rec['reason']}")
            lines.append("")
        return '\n'.join(lines)
    
    def _format_opportunities(self, opportunities: List) -> str:
        """æ ¼å¼åŒ–æœºä¼š"""
        lines = []
        for opp in opportunities:
            lines.append(f"### {opp['type']}")
            lines.append(f"**æœºä¼š**: {opp['opportunity']}")
            lines.append(f"**æ½œåŠ›**: {opp['potential']}")
            lines.append("")
        return '\n'.join(lines)

def main():
    """ä¸»å‡½æ•°"""
    analyzer = CarDesignTrendAnalyzer()
    
    if not analyzer.models_data:
        print("âŒ æ²¡æœ‰å¯åˆ†æçš„æ•°æ®ï¼Œè¯·å…ˆè¿è¡Œé‡‡é›†å™¨")
        return
    
    try:
        # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        report = analyzer.generate_comprehensive_report()
        
        # ä¿å­˜æŠ¥å‘Š
        analyzer.save_report(report)
        
        print(f"\nâœ… è¶‹åŠ¿åˆ†æå®Œæˆï¼")
        print(f"ğŸ“Š åˆ†æäº† {len(analyzer.models_data)} ä¸ªæ±½è½¦æ¨¡å‹")
        print(f"ğŸ“ˆ ç”Ÿæˆäº† {len(report['design_recommendations'])} æ¡è®¾è®¡å»ºè®®")
        print(f"ğŸš€ è¯†åˆ«äº† {len(report['market_opportunities'])} ä¸ªå¸‚åœºæœºä¼š")
        print(f"ğŸ“ æŠ¥å‘Šä¿å­˜åœ¨ {analyzer.output_dir}/ ç›®å½•ä¸­")
        
    except Exception as e:
        print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
