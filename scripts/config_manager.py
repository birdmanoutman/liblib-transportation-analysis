#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é…ç½®ç®¡ç†æ¨¡å—
æ”¯æŒé…ç½®æ–‡ä»¶åŠ è½½ã€å‘½ä»¤è¡Œå‚æ•°è¦†ç›–å’Œé…ç½®éªŒè¯

åŠŸèƒ½ç‰¹æ€§ï¼š
- ğŸ“ å¤šçº§é…ç½®æ–‡ä»¶æ”¯æŒ
- ğŸ”§ å‘½ä»¤è¡Œå‚æ•°è¦†ç›–
- âœ… é…ç½®éªŒè¯å’Œé»˜è®¤å€¼
- ğŸŒ ç¯å¢ƒå˜é‡æ”¯æŒ
- ğŸ“ é…ç½®æ¨¡æ¿ç”Ÿæˆ
"""

import os
import json
import logging
from pathlib import Path
from typing import Dict, Any, Optional, List, Union
from dataclasses import dataclass, field
import argparse

@dataclass
class ConfigManager:
    """é…ç½®ç®¡ç†å™¨"""
    
    config_file: Optional[str] = None
    config_data: Dict[str, Any] = field(default_factory=dict)
    logger: Optional[logging.Logger] = None
    
    def __post_init__(self):
        """åˆå§‹åŒ–åå¤„ç†"""
        if not self.logger:
            self.logger = logging.getLogger(__name__)
    
    def load_config(self, config_path: Optional[str] = None) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤è·¯å¾„
            
        Returns:
            é…ç½®å­—å…¸
        """
        if config_path:
            self.config_file = config_path
        elif not self.config_file:
            # æŸ¥æ‰¾é…ç½®æ–‡ä»¶
            self.config_file = self._find_config_file()
        
        defaults = self._get_default_config()
        if self.config_file and os.path.exists(self.config_file):
            try:
                with open(self.config_file, 'r', encoding='utf-8') as f:
                    loaded = json.load(f)
                # æ·±åº¦åˆå¹¶ï¼šä»¥ loaded è¦†ç›– defaults
                self.config_data = self._merge_config(defaults, loaded)
                self.logger.info(f"é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ: {self.config_file}")
            except Exception as e:
                self.logger.error(f"é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
                self.config_data = defaults
        else:
            self.logger.info("ä½¿ç”¨é»˜è®¤é…ç½®")
            self.config_data = defaults
        
        # åº”ç”¨ç¯å¢ƒå˜é‡è¦†ç›–
        self._apply_environment_overrides()
        # åŒæ­¥æ‰å¹³æ´¾ç”Ÿé”®ï¼Œç¡®ä¿è¦†ç›–åä¹Ÿç”Ÿæ•ˆ
        self._sync_derived_keys()
        
        return self.config_data

    def _merge_config(self, base: Dict[str, Any], override: Dict[str, Any]) -> Dict[str, Any]:
        """æ·±åº¦åˆå¹¶é…ç½®ï¼Œoverride è¦†ç›– baseã€‚"""
        result = base.copy()
        for key, value in (override or {}).items():
            if isinstance(value, dict) and isinstance(result.get(key), dict):
                result[key] = self._merge_config(result[key], value)
            else:
                result[key] = value
        # ç»´æŠ¤æ´¾ç”Ÿæ‰å¹³é”®ï¼Œç¡®ä¿ Analyzer å¯ç”¨
        result["api_base"] = result.get("api_base") or result.get("api", {}).get("base_url")
        result["base_url"] = result.get("base_url") or "https://www.liblib.art"
        result["page_size"] = result.get("page_size") or result.get("scraping", {}).get("page_size", 24)
        result["max_workers"] = result.get("max_workers") or result.get("scraping", {}).get("max_workers", 4)
        if not result.get("car_keywords"):
            result["car_keywords"] = result.get("tags", {}).get("enabled", [])
        return result

    def _sync_derived_keys(self) -> None:
        """ä»åµŒå¥—é…ç½®åŒæ­¥ç”Ÿæˆ Analyzer ä½¿ç”¨çš„æ‰å¹³é”®ã€‚"""
        api = self.config_data.get("api", {}) or {}
        scraping = self.config_data.get("scraping", {}) or {}
        tags = self.config_data.get("tags", {}) or {}
        if api.get("base_url"):
            self.config_data["api_base"] = api.get("base_url")
        if not self.config_data.get("base_url"):
            self.config_data["base_url"] = "https://www.liblib.art"
        if scraping.get("page_size") and not self.config_data.get("page_size"):
            self.config_data["page_size"] = scraping.get("page_size")
        if scraping.get("max_workers") and not self.config_data.get("max_workers"):
            self.config_data["max_workers"] = scraping.get("max_workers")
        if not self.config_data.get("car_keywords"):
            self.config_data["car_keywords"] = tags.get("enabled", [])
    
    def _find_config_file(self) -> Optional[str]:
        """æŸ¥æ‰¾é…ç½®æ–‡ä»¶
        
        ä¼˜å…ˆçº§ï¼š
        1. å½“å‰ç›®å½•çš„ config.json
        2. å½“å‰ç›®å½•çš„ config/default.json
        3. ç”¨æˆ·ä¸»ç›®å½•çš„ .liblib/config.json
        """
        search_paths = [
            "config.json",
            "config/default.json",
            os.path.expanduser("~/.liblib/config.json")
        ]
        
        for path in search_paths:
            if os.path.exists(path):
                return path
        
        return None
    
    def _get_default_config(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤é…ç½®"""
        cfg = {
            "api": {
                "base_url": "https://api2.liblib.art",
                "timeout": 30,
                "retry_times": 3,
                "retry_delay": 2
            },
            "scraping": {
                "page_size": 48,
                "max_pages": 10,
                "delay_between_pages": 1,
                "max_workers": 4
            },
            "tags": {
                "enabled": ["æ±½è½¦", "è½¦", "è·‘è½¦", "è¶…è·‘", "è½¿è½¦", "SUV"],
                "disabled": [],
                "custom_keywords": []
            },
            "sorting": {
                "field": "downloads",
                "order": "desc",
                "available_fields": ["downloads", "likes", "created_at", "updated_at", "name"]
            },
            "download": {
                "concurrent_downloads": 5,
                "image_formats": ["jpg", "png", "webp"],
                "retry_times": 3,
                "skip_existing": True
            },
            "storage": {
                "output_dir": "liblib_analysis_output",
                "images_dir": "images",
                "data_dir": "data",
                "reports_dir": "reports",
                "logs_dir": "logs"
            },
            "analysis": {
                "include_charts": True,
                "report_format": "markdown",
                "language": "zh"
            },
            "logging": {
                "level": "INFO",
                "file_logging": True,
                "console_logging": True
            }
        }

        # å…¼å®¹ Analyzer ç›´æ¥è®¿é—®çš„æ‰å¹³é”®
        cfg["api_base"] = cfg["api"]["base_url"]
        cfg["base_url"] = "https://www.liblib.art"
        cfg["page_size"] = cfg["scraping"]["page_size"]
        cfg["max_workers"] = cfg["scraping"]["max_workers"]
        cfg["car_keywords"] = cfg["tags"]["enabled"]

        return cfg
    
    def _apply_environment_overrides(self):
        """åº”ç”¨ç¯å¢ƒå˜é‡è¦†ç›–"""
        env_mappings = {
            "LIBLIB_API_BASE_URL": ("api", "base_url"),
            "LIBLIB_TIMEOUT": ("api", "timeout"),
            "LIBLIB_COOKIE": ("api", "cookie"),
            "LIBLIB_MAX_WORKERS": ("scraping", "max_workers"),
            "LIBLIB_OUTPUT_DIR": ("storage", "output_dir"),
            "LIBLIB_CONCURRENT_DOWNLOADS": ("download", "concurrent_downloads"),
            "LIBLIB_LOG_LEVEL": ("logging", "level")
        }
        
        for env_var, config_path in env_mappings.items():
            env_value = os.getenv(env_var)
            if env_value:
                self._set_nested_value(config_path, env_value)
                self.logger.debug(f"ç¯å¢ƒå˜é‡è¦†ç›–: {env_var} = {env_value}")
    
    def _set_nested_value(self, path: tuple, value: Any):
        """è®¾ç½®åµŒå¥—é…ç½®å€¼"""
        current = self.config_data
        for key in path[:-1]:
            if key not in current:
                current[key] = {}
            current = current[key]
        
        # ç±»å‹è½¬æ¢
        if isinstance(current.get(path[-1]), bool):
            if isinstance(value, str):
                value = value.lower() in ('true', '1', 'yes', 'on')
        elif isinstance(current.get(path[-1]), int):
            try:
                value = int(value)
            except (ValueError, TypeError):
                pass
        elif isinstance(current.get(path[-1]), float):
            try:
                value = float(value)
            except (ValueError, TypeError):
                pass
        
        current[path[-1]] = value
    
    def get(self, key_path: str, default: Any = None) -> Any:
        """è·å–é…ç½®å€¼
        
        Args:
            key_path: é…ç½®é”®è·¯å¾„ï¼Œå¦‚ "api.base_url"
            default: é»˜è®¤å€¼
            
        Returns:
            é…ç½®å€¼
        """
        keys = key_path.split('.')
        current = self.config_data
        
        for key in keys:
            if isinstance(current, dict) and key in current:
                current = current[key]
            else:
                return default
        
        return current
    
    def set(self, key_path: str, value: Any):
        """è®¾ç½®é…ç½®å€¼
        
        Args:
            key_path: é…ç½®é”®è·¯å¾„ï¼Œå¦‚ "api.base_url"
            value: é…ç½®å€¼
        """
        keys = key_path.split('.')
        current = self.config_data
        
        for key in keys[:-1]:
            if key not in current:
                current[key] = {}
            current = current[key]
        
        current[keys[-1]] = value
    
    def update_from_args(self, args: argparse.Namespace):
        """ä»å‘½ä»¤è¡Œå‚æ•°æ›´æ–°é…ç½®
        
        Args:
            args: è§£æåçš„å‘½ä»¤è¡Œå‚æ•°
        """
        # æ ‡ç­¾ç›¸å…³
        if hasattr(args, 'tags') and args.tags:
            self.set('tags.enabled', args.tags.split(','))
        
        if hasattr(args, 'exclude_tags') and args.exclude_tags:
            self.set('tags.disabled', args.exclude_tags.split(','))
        
        if hasattr(args, 'custom_keywords') and args.custom_keywords:
            self.set('tags.custom_keywords', args.custom_keywords.split(','))
        
        # æ’åºç›¸å…³
        if hasattr(args, 'sort_by') and args.sort_by:
            if args.sort_by in self.get('sorting.available_fields', []):
                self.set('sorting.field', args.sort_by)
            else:
                self.logger.warning(f"ä¸æ”¯æŒçš„æ’åºå­—æ®µ: {args.sort_by}")
        
        if hasattr(args, 'sort_order') and args.sort_order:
            if args.sort_order in ['asc', 'desc']:
                self.set('sorting.order', args.sort_order)
            else:
                self.logger.warning(f"ä¸æ”¯æŒçš„æ’åºé¡ºåº: {args.sort_order}")
        
        # é¡µèŒƒå›´ç›¸å…³
        if hasattr(args, 'max_pages') and args.max_pages:
            self.set('scraping.max_pages', args.max_pages)
        
        if hasattr(args, 'page_size') and args.page_size:
            self.set('scraping.page_size', args.page_size)
        
        # å¹¶å‘ç›¸å…³
        if hasattr(args, 'max_workers') and args.max_workers:
            self.set('scraping.max_workers', args.max_workers)
        
        if hasattr(args, 'concurrent_downloads') and args.concurrent_downloads:
            self.set('download.concurrent_downloads', args.concurrent_downloads)
        
        # å­˜å‚¨è·¯å¾„ç›¸å…³
        if hasattr(args, 'output_dir') and args.output_dir:
            self.set('storage.output_dir', args.output_dir)
        
        if hasattr(args, 'images_dir') and args.images_dir:
            self.set('storage.images_dir', args.images_dir)
        
        # æ—¥å¿—ç›¸å…³
        if hasattr(args, 'log_level') and args.log_level:
            self.set('logging.level', args.log_level.upper())
        
        if hasattr(args, 'verbose') and args.verbose:
            self.set('logging.level', 'DEBUG')
    
    def validate_config(self) -> List[str]:
        """éªŒè¯é…ç½®
        
        Returns:
            é”™è¯¯ä¿¡æ¯åˆ—è¡¨
        """
        errors = []
        
        # éªŒè¯APIé…ç½®
        if not self.get('api.base_url'):
            errors.append("APIåŸºç¡€URLä¸èƒ½ä¸ºç©º")
        
        if self.get('api.timeout', 0) <= 0:
            errors.append("APIè¶…æ—¶æ—¶é—´å¿…é¡»å¤§äº0")
        
        # éªŒè¯çˆ¬å–é…ç½®
        if self.get('scraping.max_pages', 0) <= 0:
            errors.append("æœ€å¤§é¡µæ•°å¿…é¡»å¤§äº0")
        
        if self.get('scraping.page_size', 0) <= 0:
            errors.append("é¡µå¤§å°å¿…é¡»å¤§äº0")
        
        if self.get('scraping.max_workers', 0) <= 0:
            errors.append("æœ€å¤§å·¥ä½œçº¿ç¨‹æ•°å¿…é¡»å¤§äº0")
        
        # éªŒè¯ä¸‹è½½é…ç½®
        if self.get('download.concurrent_downloads', 0) <= 0:
            errors.append("å¹¶å‘ä¸‹è½½æ•°å¿…é¡»å¤§äº0")
        
        # éªŒè¯æ ‡ç­¾é…ç½®
        enabled_tags = self.get('tags.enabled', [])
        if not enabled_tags:
            errors.append("è‡³å°‘éœ€è¦å¯ç”¨ä¸€ä¸ªæ ‡ç­¾")
        
        # éªŒè¯æ’åºé…ç½®
        sort_field = self.get('sorting.field')
        available_fields = self.get('sorting.available_fields', [])
        if sort_field and sort_field not in available_fields:
            errors.append(f"ä¸æ”¯æŒçš„æ’åºå­—æ®µ: {sort_field}")
        
        return errors
    
    def save_config(self, file_path: Optional[str] = None) -> bool:
        """ä¿å­˜é…ç½®åˆ°æ–‡ä»¶
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨å½“å‰é…ç½®æ–‡ä»¶è·¯å¾„
            
        Returns:
            æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        if not file_path:
            file_path = self.config_file or "config.json"
        
        try:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(file_path), exist_ok=True)
            
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(self.config_data, f, indent=2, ensure_ascii=False)
            
            self.logger.info(f"é…ç½®å·²ä¿å­˜åˆ°: {file_path}")
            return True
        except Exception as e:
            self.logger.error(f"é…ç½®ä¿å­˜å¤±è´¥: {e}")
            return False
    
    def create_config_template(self, file_path: str = "config_template.json") -> bool:
        """åˆ›å»ºé…ç½®æ¨¡æ¿æ–‡ä»¶
        
        Args:
            file_path: æ¨¡æ¿æ–‡ä»¶è·¯å¾„
            
        Returns:
            æ˜¯å¦åˆ›å»ºæˆåŠŸ
        """
        template_config = self._get_default_config()
        
        # æ·»åŠ æ³¨é‡Šè¯´æ˜
        template_config["_comment"] = {
            "api": "APIç›¸å…³é…ç½®",
            "scraping": "æ•°æ®é‡‡é›†é…ç½®",
            "tags": "æ ‡ç­¾å’Œå…³é”®è¯é…ç½®",
            "sorting": "æ’åºé…ç½®",
            "download": "ä¸‹è½½é…ç½®",
            "storage": "å­˜å‚¨è·¯å¾„é…ç½®",
            "analysis": "åˆ†æé…ç½®",
            "logging": "æ—¥å¿—é…ç½®"
        }
        
        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(template_config, f, indent=2, ensure_ascii=False)
            
            self.logger.info(f"é…ç½®æ¨¡æ¿å·²åˆ›å»º: {file_path}")
            return True
        except Exception as e:
            self.logger.error(f"é…ç½®æ¨¡æ¿åˆ›å»ºå¤±è´¥: {e}")
            return False
    
    def get_effective_config(self) -> Dict[str, Any]:
        """è·å–æœ‰æ•ˆé…ç½®ï¼ˆåŒ…å«æ‰€æœ‰é»˜è®¤å€¼ï¼‰"""
        return self.config_data.copy()
    
    def print_config_summary(self):
        """æ‰“å°é…ç½®æ‘˜è¦"""
        print("\nğŸ“‹ å½“å‰é…ç½®æ‘˜è¦:")
        print("=" * 50)
        
        # APIé…ç½®
        print(f"ğŸŒ APIåŸºç¡€URL: {self.get('api.base_url')}")
        print(f"â±ï¸  è¶…æ—¶æ—¶é—´: {self.get('api.timeout')}ç§’")
        
        # çˆ¬å–é…ç½®
        print(f"ğŸ“„ æœ€å¤§é¡µæ•°: {self.get('scraping.max_pages')}")
        print(f"ğŸ“Š é¡µå¤§å°: {self.get('scraping.page_size')}")
        print(f"ğŸ”„ æœ€å¤§å·¥ä½œçº¿ç¨‹: {self.get('scraping.max_workers')}")
        
        # æ ‡ç­¾é…ç½®
        enabled_tags = self.get('tags.enabled', [])
        print(f"ğŸ·ï¸  å¯ç”¨æ ‡ç­¾: {', '.join(enabled_tags[:5])}{'...' if len(enabled_tags) > 5 else ''}")
        
        # æ’åºé…ç½®
        print(f"ğŸ“ˆ æ’åºå­—æ®µ: {self.get('sorting.field')}")
        print(f"ğŸ“Š æ’åºé¡ºåº: {self.get('sorting.order')}")
        
        # ä¸‹è½½é…ç½®
        print(f"â¬‡ï¸  å¹¶å‘ä¸‹è½½: {self.get('download.concurrent_downloads')}")
        
        # å­˜å‚¨é…ç½®
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {self.get('storage.output_dir')}")
        
        print("=" * 50)
