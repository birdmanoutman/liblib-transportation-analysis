#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
T5 è¯¦æƒ…é‡‡é›†å™¨
å®ç° group/get/{slug}ã€author/{slug} æ¥å£è°ƒç”¨
å­—æ®µæ ¡éªŒä¸ç¼ºçœç­–ç•¥ï¼Œå¯é€‰è¯„è®ºè½åº“
"""

import os
import sys
import json
import time
import logging
import mysql.connector
from mysql.connector import Error
from dotenv import load_dotenv
from typing import Dict, List, Optional, Any, Tuple
from datetime import datetime, timezone
import requests
from concurrent.futures import ThreadPoolExecutor, as_completed
import hashlib
from urllib.parse import urlparse
import re

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('detail_collector.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class DetailCollector:
    """T5 è¯¦æƒ…é‡‡é›†å™¨"""
    
    def __init__(self, max_workers: int = 5):
        # åŠ è½½ç¯å¢ƒå˜é‡
        load_dotenv()
        
        # æ•°æ®åº“è¿æ¥é…ç½®
        self.db_config = {
            'host': os.getenv('DB_HOST'),
            'port': int(os.getenv('DB_PORT', 3306)),
            'database': os.getenv('DB_NAME'),
            'user': os.getenv('DB_USER'),
            'password': os.getenv('DB_PASSWORD'),
            'charset': 'utf8mb4',
            'collation': 'utf8mb4_unicode_ci'
        }
        
        # APIé…ç½®
        self.api_base = 'https://api2.liblib.art'
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/139.0.0.0 Safari/537.36',
            'Accept': 'application/json, text/plain, */*',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Referer': 'https://www.liblib.art/',
            'Origin': 'https://www.liblib.art'
        })
        
        # å¹¶å‘æ§åˆ¶
        self.max_workers = max_workers
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_processed': 0,
            'success_count': 0,
            'failed_count': 0,
            'authors_created': 0,
            'works_created': 0,
            'comments_created': 0,
            'start_time': datetime.now()
        }
        
        # æ•°æ®åº“è¿æ¥
        self.connection = None
        self.connect_database()
    
    def connect_database(self):
        """è¿æ¥æ•°æ®åº“"""
        try:
            self.connection = mysql.connector.connect(**self.db_config)
            if self.connection.is_connected():
                logger.info("æ•°æ®åº“è¿æ¥æˆåŠŸ")
            else:
                logger.error("æ•°æ®åº“è¿æ¥å¤±è´¥")
                raise Exception("æ•°æ®åº“è¿æ¥å¤±è´¥")
        except Error as e:
            logger.error(f"æ•°æ®åº“è¿æ¥é”™è¯¯: {e}")
            raise
    
    def get_timestamp(self) -> int:
        """è·å–å½“å‰æ—¶é—´æˆ³"""
        return int(time.time() * 1000)
    
    def safe_request(self, method: str, url: str, **kwargs) -> Optional[requests.Response]:
        """å®‰å…¨çš„HTTPè¯·æ±‚"""
        try:
            response = self.session.request(method, url, **kwargs)
            response.raise_for_status()
            return response
        except requests.RequestException as e:
            logger.error(f"è¯·æ±‚å¤±è´¥ {url}: {e}")
            time.sleep(2)
            return None
    
    def get_work_detail(self, slug: str) -> Optional[Dict[str, Any]]:
        """è·å–ä½œå“è¯¦æƒ… - group/get/{slug}"""
        url = f"{self.api_base}/api/www/img/group/get/{slug}"
        
        payload = {
            "timestamp": self.get_timestamp()
        }
        
        logger.debug(f"è·å–ä½œå“è¯¦æƒ…: {slug}")
        
        response = self.safe_request('POST', url, json=payload)
        if response:
            try:
                data = response.json()
                if data.get('code') == 0:
                    return data.get('data', {})
                else:
                    logger.warning(f"ä½œå“è¯¦æƒ…æ¥å£è¿”å›é”™è¯¯: {data.get('message', 'Unknown error')}")
            except json.JSONDecodeError:
                logger.error(f"ä½œå“è¯¦æƒ…å“åº”æ ¼å¼é”™è¯¯: {slug}")
        
        return None
    
    def get_author_detail(self, author_slug: str) -> Optional[Dict[str, Any]]:
        """è·å–ä½œè€…è¯¦æƒ… - author/{slug}"""
        url = f"{self.api_base}/api/www/img/author/{author_slug}"
        
        params = {
            "timestamp": self.get_timestamp()
        }
        
        logger.debug(f"è·å–ä½œè€…è¯¦æƒ…: {author_slug}")
        
        response = self.safe_request('POST', url, params=params)
        if response:
            try:
                data = response.json()
                if data.get('code') == 0:
                    return data.get('data', {})
                else:
                    logger.warning(f"ä½œè€…è¯¦æƒ…æ¥å£è¿”å›é”™è¯¯: {data.get('message', 'Unknown error')}")
            except json.JSONDecodeError:
                logger.error(f"ä½œè€…è¯¦æƒ…å“åº”æ ¼å¼é”™è¯¯: {author_slug}")
        
        return None
    
    def get_work_comments(self, work_id: int, slug: str) -> List[Dict[str, Any]]:
        """è·å–ä½œå“è¯„è®ºï¼ˆå¯é€‰ï¼‰"""
        url = f"{self.api_base}/api/www/community/commentList"
        
        payload = {
            "workId": work_id,
            "page": 1,
            "pageSize": 50,
            "sortType": "hot",
            "timestamp": self.get_timestamp()
        }
        
        logger.debug(f"è·å–ä½œå“è¯„è®º: {slug}")
        
        response = self.safe_request('POST', url, json=payload)
        if response:
            try:
                data = response.json()
                if data.get('code') == 0:
                    return data.get('data', {}).get('list', [])
                else:
                    logger.warning(f"è¯„è®ºæ¥å£è¿”å›é”™è¯¯: {data.get('message', 'Unknown error')}")
            except json.JSONDecodeError:
                logger.error(f"è¯„è®ºå“åº”æ ¼å¼é”™è¯¯: {slug}")
        
        return []
    
    def validate_and_default_work_data(self, work_data: Dict[str, Any]) -> Dict[str, Any]:
        """å­—æ®µæ ¡éªŒä¸ç¼ºçœç­–ç•¥ - ä½œå“æ•°æ®"""
        validated = {}
        
        # å¿…å¡«å­—æ®µæ ¡éªŒ
        required_fields = ['slug', 'title']
        for field in required_fields:
            if not work_data.get(field):
                logger.warning(f"ä½œå“ç¼ºå°‘å¿…å¡«å­—æ®µ: {field}")
                return {}
        
        # åŸºç¡€å­—æ®µ
        validated['slug'] = work_data.get('slug', '')
        validated['title'] = work_data.get('title', '')
        validated['published_at'] = self.parse_datetime(work_data.get('publishedAt'))
        
        # æ ‡ç­¾å¤„ç†
        tags = work_data.get('tags', [])
        if isinstance(tags, list):
            validated['tags_json'] = json.dumps(tags, ensure_ascii=False)
        else:
            validated['tags_json'] = json.dumps([], ensure_ascii=False)
        
        # æç¤ºè¯å¤„ç†
        validated['prompt'] = work_data.get('prompt', '') or ''
        validated['negative_prompt'] = work_data.get('negativePrompt', '') or ''
        
        # ç”Ÿæˆå‚æ•°
        validated['sampler'] = work_data.get('sampler', '') or ''
        validated['steps'] = work_data.get('steps', 0) or 0
        validated['cfg_scale'] = float(work_data.get('cfgScale', 0)) or 0.0
        validated['width'] = work_data.get('width', 0) or 0
        validated['height'] = work_data.get('height', 0) or 0
        validated['seed'] = str(work_data.get('seed', '')) or ''
        
        # ç»Ÿè®¡æ•°æ®
        validated['like_count'] = work_data.get('likeCount', 0) or 0
        validated['favorite_count'] = work_data.get('favoriteCount', 0) or 0
        validated['comment_count'] = work_data.get('commentCount', 0) or 0
        
        # æºURL
        validated['source_url'] = work_data.get('sourceUrl', '') or ''
        
        return validated
    
    def validate_and_default_author_data(self, author_data: Dict[str, Any]) -> Dict[str, Any]:
        """å­—æ®µæ ¡éªŒä¸ç¼ºçœç­–ç•¥ - ä½œè€…æ•°æ®"""
        validated = {}
        
        # å¿…å¡«å­—æ®µæ ¡éªŒ
        if not author_data.get('name'):
            logger.warning("ä½œè€…ç¼ºå°‘å¿…å¡«å­—æ®µ: name")
            return {}
        
        # åŸºç¡€å­—æ®µ
        validated['external_author_id'] = author_data.get('id', '') or ''
        validated['name'] = author_data.get('name', '')
        validated['avatar_url'] = author_data.get('avatar', '') or ''
        validated['profile_url'] = author_data.get('profileUrl', '') or ''
        validated['created_at'] = self.parse_datetime(author_data.get('createdAt'))
        
        return validated
    
    def parse_datetime(self, timestamp: Any) -> Optional[datetime]:
        """è§£ææ—¶é—´æˆ³"""
        if not timestamp:
            return None
        
        try:
            if isinstance(timestamp, (int, float)):
                # æ¯«ç§’æ—¶é—´æˆ³
                if timestamp > 1e10:  # æ¯«ç§’
                    timestamp = timestamp / 1000
                return datetime.fromtimestamp(timestamp, tz=timezone.utc)
            elif isinstance(timestamp, str):
                # ISOæ ¼å¼å­—ç¬¦ä¸²
                return datetime.fromisoformat(timestamp.replace('Z', '+00:00'))
        except (ValueError, TypeError):
            logger.warning(f"æ— æ³•è§£ææ—¶é—´æˆ³: {timestamp}")
        
        return None
    
    def create_author(self, author_data: Dict[str, Any]) -> Optional[int]:
        """åˆ›å»ºä½œè€…è®°å½•"""
        try:
            cursor = self.connection.cursor()
            
            # æ£€æŸ¥ä½œè€…æ˜¯å¦å·²å­˜åœ¨
            check_sql = "SELECT id FROM authors WHERE name = %s"
            cursor.execute(check_sql, (author_data['name'],))
            existing = cursor.fetchone()
            
            if existing:
                logger.debug(f"ä½œè€…å·²å­˜åœ¨: {author_data['name']} (ID: {existing[0]})")
                return existing[0]
            
            # æ’å…¥æ–°ä½œè€…
            insert_sql = """
                INSERT INTO authors (external_author_id, name, avatar_url, profile_url, created_at)
                VALUES (%s, %s, %s, %s, %s)
            """
            cursor.execute(insert_sql, (
                author_data['external_author_id'],
                author_data['name'],
                author_data['avatar_url'],
                author_data['profile_url'],
                author_data['created_at']
            ))
            
            author_id = cursor.lastrowid
            self.connection.commit()
            
            logger.info(f"åˆ›å»ºä½œè€…æˆåŠŸ: {author_data['name']} (ID: {author_id})")
            self.stats['authors_created'] += 1
            
            return author_id
            
        except Error as e:
            logger.error(f"åˆ›å»ºä½œè€…å¤±è´¥: {e}")
            self.connection.rollback()
            return None
    
    def create_work(self, work_data: Dict[str, Any], author_id: Optional[int]) -> Optional[int]:
        """åˆ›å»ºä½œå“è®°å½•"""
        try:
            cursor = self.connection.cursor()
            
            # æ£€æŸ¥ä½œå“æ˜¯å¦å·²å­˜åœ¨
            check_sql = "SELECT id FROM works WHERE slug = %s"
            cursor.execute(check_sql, (work_data['slug'],))
            existing = cursor.fetchone()
            
            if existing:
                logger.debug(f"ä½œå“å·²å­˜åœ¨: {work_data['slug']} (ID: {existing[0]})")
                return existing[0]
            
            # æ’å…¥æ–°ä½œå“
            insert_sql = """
                INSERT INTO works (
                    slug, title, published_at, tags_json, prompt, negative_prompt,
                    sampler, steps, cfg_scale, width, height, seed,
                    like_count, favorite_count, comment_count, source_url, author_id
                ) VALUES (
                    %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s
                )
            """
            cursor.execute(insert_sql, (
                work_data['slug'],
                work_data['title'],
                work_data['published_at'],
                work_data['tags_json'],
                work_data['prompt'],
                work_data['negative_prompt'],
                work_data['sampler'],
                work_data['steps'],
                work_data['cfg_scale'],
                work_data['width'],
                work_data['height'],
                work_data['seed'],
                work_data['like_count'],
                work_data['favorite_count'],
                work_data['comment_count'],
                work_data['source_url'],
                author_id
            ))
            
            work_id = cursor.lastrowid
            self.connection.commit()
            
            logger.info(f"åˆ›å»ºä½œå“æˆåŠŸ: {work_data['title']} (ID: {work_id})")
            self.stats['works_created'] += 1
            
            return work_id
            
        except Error as e:
            logger.error(f"åˆ›å»ºä½œå“å¤±è´¥: {e}")
            self.connection.rollback()
            return None
    
    def create_comments(self, work_id: int, comments: List[Dict[str, Any]]) -> int:
        """åˆ›å»ºè¯„è®ºè®°å½•"""
        if not comments:
            return 0
        
        created_count = 0
        
        try:
            cursor = self.connection.cursor()
            
            for comment in comments:
                # æ£€æŸ¥è¯„è®ºæ˜¯å¦å·²å­˜åœ¨ï¼ˆåŸºäºå†…å®¹å’Œæ—¶é—´ï¼‰
                comment_content = comment.get('content', '')
                comment_time = self.parse_datetime(comment.get('commentedAt'))
                
                if not comment_content or not comment_time:
                    continue
                
                # ç®€å•çš„é‡å¤æ£€æŸ¥
                check_sql = """
                    SELECT id FROM comments 
                    WHERE work_id = %s AND content = %s AND commented_at = %s
                """
                cursor.execute(check_sql, (work_id, comment_content, comment_time))
                existing = cursor.fetchone()
                
                if existing:
                    continue
                
                # æ’å…¥æ–°è¯„è®º
                insert_sql = """
                    INSERT INTO comments (work_id, commenter_name, commenter_avatar_url, content, commented_at)
                    VALUES (%s, %s, %s, %s, %s)
                """
                cursor.execute(insert_sql, (
                    work_id,
                    comment.get('commenterName', ''),
                    comment.get('commenterAvatar', ''),
                    comment_content,
                    comment_time
                ))
                
                created_count += 1
            
            self.connection.commit()
            
            if created_count > 0:
                logger.info(f"åˆ›å»ºè¯„è®ºæˆåŠŸ: {created_count} æ¡")
                self.stats['comments_created'] += created_count
            
        except Error as e:
            logger.error(f"åˆ›å»ºè¯„è®ºå¤±è´¥: {e}")
            self.connection.rollback()
        
        return created_count
    
    def process_single_work(self, slug: str) -> bool:
        """å¤„ç†å•ä¸ªä½œå“çš„è¯¦æƒ…é‡‡é›†"""
        try:
            logger.info(f"å¼€å§‹å¤„ç†ä½œå“: {slug}")
            
            # 1. è·å–ä½œå“è¯¦æƒ…
            work_detail = self.get_work_detail(slug)
            if not work_detail:
                logger.error(f"æ— æ³•è·å–ä½œå“è¯¦æƒ…: {slug}")
                return False
            
            # 2. å­—æ®µæ ¡éªŒä¸ç¼ºçœ
            validated_work = self.validate_and_default_work_data(work_detail)
            if not validated_work:
                logger.error(f"ä½œå“æ•°æ®éªŒè¯å¤±è´¥: {slug}")
                return False
            
            # 3. è·å–ä½œè€…ä¿¡æ¯
            author_slug = work_detail.get('authorSlug', '')
            author_id = None
            
            if author_slug:
                author_detail = self.get_author_detail(author_slug)
                if author_detail:
                    validated_author = self.validate_and_default_author_data(author_detail)
                    if validated_author:
                        author_id = self.create_author(validated_author)
            
            # 4. åˆ›å»ºä½œå“è®°å½•
            work_id = self.create_work(validated_work, author_id)
            if not work_id:
                logger.error(f"åˆ›å»ºä½œå“è®°å½•å¤±è´¥: {slug}")
                return False
            
            # 5. è·å–å¹¶åˆ›å»ºè¯„è®ºï¼ˆå¯é€‰ï¼‰
            if work_detail.get('commentCount', 0) > 0:
                comments = self.get_work_comments(work_id, slug)
                if comments:
                    self.create_comments(work_id, comments)
            
            # 6. å¤„ç†æ¨¡å‹å¼•ç”¨ï¼ˆå¦‚æœæœ‰ï¼‰
            self.process_model_references(work_id, work_detail)
            
            logger.info(f"ä½œå“å¤„ç†å®Œæˆ: {slug}")
            return True
            
        except Exception as e:
            logger.error(f"å¤„ç†ä½œå“å¼‚å¸¸ {slug}: {e}")
            return False
    
    def process_model_references(self, work_id: int, work_detail: Dict[str, Any]):
        """å¤„ç†æ¨¡å‹å¼•ç”¨"""
        try:
            # è¿™é‡Œå¯ä»¥æ ¹æ®å®é™…APIå“åº”ç»“æ„æ¥æå–æ¨¡å‹å¼•ç”¨ä¿¡æ¯
            # ç›®å‰å…ˆé¢„ç•™æ¥å£
            pass
        except Exception as e:
            logger.error(f"å¤„ç†æ¨¡å‹å¼•ç”¨å¤±è´¥: {e}")
    
    def collect_details_batch(self, slugs: List[str]) -> Dict[str, Any]:
        """æ‰¹é‡é‡‡é›†è¯¦æƒ…"""
        logger.info(f"å¼€å§‹æ‰¹é‡é‡‡é›†è¯¦æƒ…ï¼Œå…± {len(slugs)} ä¸ªä½œå“")
        
        self.stats['total_processed'] = len(slugs)
        self.stats['start_time'] = datetime.now()
        
        # å¹¶å‘å¤„ç†
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            future_to_slug = {
                executor.submit(self.process_single_work, slug): slug 
                for slug in slugs
            }
            
            for future in as_completed(future_to_slug):
                slug = future_to_slug[future]
                try:
                    success = future.result()
                    if success:
                        self.stats['success_count'] += 1
                    else:
                        self.stats['failed_count'] += 1
                except Exception as e:
                    logger.error(f"å¤„ç†ä½œå“å¼‚å¸¸ {slug}: {e}")
                    self.stats['failed_count'] += 1
        
        # è®¡ç®—æˆåŠŸç‡
        success_rate = (self.stats['success_count'] / self.stats['total_processed']) * 100 if self.stats['total_processed'] > 0 else 0
        
        logger.info(f"æ‰¹é‡é‡‡é›†å®Œæˆï¼ŒæˆåŠŸç‡: {success_rate:.2f}%")
        logger.info(f"æˆåŠŸ: {self.stats['success_count']}, å¤±è´¥: {self.stats['failed_count']}")
        
        return self.stats
    
    def get_collection_stats(self) -> Dict[str, Any]:
        """è·å–é‡‡é›†ç»Ÿè®¡"""
        return {
            'total_processed': self.stats['total_processed'],
            'success_count': self.stats['success_count'],
            'failed_count': self.stats['failed_count'],
            'success_rate': (self.stats['success_count'] / self.stats['total_processed']) * 100 if self.stats['total_processed'] > 0 else 0,
            'authors_created': self.stats['authors_created'],
            'works_created': self.stats['works_created'],
            'comments_created': self.stats['comments_created'],
            'start_time': self.stats['start_time'].isoformat(),
            'duration': (datetime.now() - self.stats['start_time']).total_seconds()
        }
    
    def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        if self.connection and self.connection.is_connected():
            self.connection.close()
            logger.info("æ•°æ®åº“è¿æ¥å·²å…³é—­")

def main():
    """ä¸»å‡½æ•° - æµ‹è¯•è¯¦æƒ…é‡‡é›†å™¨"""
    # æµ‹è¯•ç”¨çš„slugåˆ—è¡¨
    test_slugs = [
        "test-slug-1",
        "test-slug-2"
    ]
    
    collector = DetailCollector(max_workers=3)
    
    try:
        # æ‰¹é‡é‡‡é›†è¯¦æƒ…
        stats = collector.collect_details_batch(test_slugs)
        
        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        print("\nâœ… è¯¦æƒ…é‡‡é›†å®Œæˆï¼")
        print(f"ğŸ“Š é‡‡é›†ç»Ÿè®¡:")
        print(f"   æ€»å¤„ç†æ•°: {stats['total_processed']}")
        print(f"   æˆåŠŸæ•°: {stats['success_count']}")
        print(f"   å¤±è´¥æ•°: {stats['failed_count']}")
        print(f"   æˆåŠŸç‡: {stats.get('success_rate', 0):.2f}%")
        print(f"   åˆ›å»ºä½œè€…: {stats['authors_created']}")
        print(f"   åˆ›å»ºä½œå“: {stats['works_created']}")
        print(f"   åˆ›å»ºè¯„è®º: {stats['comments_created']}")
        
    except KeyboardInterrupt:
        print("\nâŒ ç”¨æˆ·ä¸­æ–­é‡‡é›†")
    except Exception as e:
        logger.error(f"é‡‡é›†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
    finally:
        collector.close()

if __name__ == "__main__":
    main()
