#!/usr/bin/env python3
"""
åˆ†æMCPå·¥å…·é‡‡é›†åˆ°çš„Liblibæ±½è½¦äº¤é€šæ¨¡å‹æ•°æ®
"""

import json
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import logging
from typing import Dict, List, Any
import re

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class MCPDataAnalyzer:
    """åˆ†æMCPå·¥å…·é‡‡é›†çš„æ•°æ®"""
    
    def __init__(self, data_dir: str = "data/raw/liblib/mcp_collection"):
        self.data_dir = Path(data_dir)
        self.data = None
        self.df = None
        
    def load_latest_data(self) -> bool:
        """åŠ è½½æœ€æ–°çš„æ•°æ®æ–‡ä»¶"""
        try:
            # æŸ¥æ‰¾æœ€æ–°çš„JSONæ–‡ä»¶
            json_files = list(self.data_dir.glob("car_models_*.json"))
            if not json_files:
                logger.error(f"åœ¨ {self.data_dir} ä¸­æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶")
                return False
                
            latest_file = max(json_files, key=lambda x: x.stat().st_mtime)
            logger.info(f"åŠ è½½æ•°æ®æ–‡ä»¶: {latest_file}")
            
            with open(latest_file, 'r', encoding='utf-8') as f:
                self.data = json.load(f)
                
            # è½¬æ¢ä¸ºDataFrame
            self.df = pd.DataFrame(self.data)
            logger.info(f"æˆåŠŸåŠ è½½ {len(self.df)} æ¡æ•°æ®")
            return True
            
        except Exception as e:
            logger.error(f"åŠ è½½æ•°æ®å¤±è´¥: {e}")
            return False
    
    def analyze_downloads(self) -> Dict[str, Any]:
        """åˆ†æä¸‹è½½é‡æ•°æ®"""
        if self.df is None:
            return {}
            
        # æ¸…ç†ä¸‹è½½é‡æ•°æ®ï¼ˆç§»é™¤k, Mç­‰åç¼€ï¼‰
        def clean_downloads(download_str):
            if pd.isna(download_str):
                return 0
            download_str = str(download_str)
            if 'k' in download_str.lower():
                return float(download_str.lower().replace('k', '')) * 1000
            elif 'm' in download_str.lower():
                return float(download_str.lower().replace('m', '')) * 1000000
            else:
                try:
                    return float(download_str)
                except:
                    return 0
        
        self.df['downloads_clean'] = self.df['downloads'].apply(clean_downloads)
        
        analysis = {
            'total_downloads': int(self.df['downloads_clean'].sum()),
            'avg_downloads': int(self.df['downloads_clean'].mean()),
            'max_downloads': int(self.df['downloads_clean'].max()),
            'min_downloads': int(self.df['downloads_clean'].min()),
            'download_distribution': self.df['downloads_clean'].describe().to_dict()
        }
        
        return analysis
    
    def analyze_authors(self) -> Dict[str, Any]:
        """åˆ†æä½œè€…æ•°æ®"""
        if self.df is None:
            return {}
            
        author_stats = self.df.groupby('author').agg({
            'title': 'count',
            'downloads_clean': 'sum',
            'likes': lambda x: sum(int(str(i)) for i in x if str(i).isdigit()),
            'collections': lambda x: sum(int(str(i)) for i in x if str(i).isdigit())
        }).rename(columns={
            'title': 'model_count',
            'downloads_clean': 'total_downloads',
            'likes': 'total_likes',
            'collections': 'total_collections'
        })
        
        return {
            'total_authors': len(author_stats),
            'author_stats': author_stats.to_dict('index'),
            'top_authors_by_models': author_stats.nlargest(3, 'model_count').to_dict('index'),
            'top_authors_by_downloads': author_stats.nlargest(3, 'total_downloads').to_dict('index')
        }
    
    def analyze_model_types(self) -> Dict[str, Any]:
        """åˆ†ææ¨¡å‹ç±»å‹æ•°æ®"""
        if self.df is None:
            return {}
            
        type_stats = self.df['type'].value_counts().to_dict()
        version_stats = self.df['version'].value_counts().to_dict()
        
        return {
            'type_distribution': type_stats,
            'version_distribution': version_stats,
            'total_types': len(type_stats),
            'total_versions': len(version_stats)
        }
    
    def generate_visualizations(self, output_dir: str = "data/processed/mcp_analysis"):
        """ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨"""
        if self.df is None:
            logger.error("æ²¡æœ‰æ•°æ®å¯ä»¥å¯è§†åŒ–")
            return
            
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        # è®¾ç½®ä¸­æ–‡å­—ä½“
        plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        
        # 1. ä¸‹è½½é‡åˆ†å¸ƒ
        plt.figure(figsize=(10, 6))
        self.df['downloads_clean'].hist(bins=20, alpha=0.7, color='skyblue', edgecolor='black')
        plt.title('æ¨¡å‹ä¸‹è½½é‡åˆ†å¸ƒ')
        plt.xlabel('ä¸‹è½½é‡')
        plt.ylabel('æ¨¡å‹æ•°é‡')
        plt.grid(True, alpha=0.3)
        plt.savefig(output_path / 'downloads_distribution.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        # 2. ä½œè€…æ¨¡å‹æ•°é‡
        author_counts = self.df['author'].value_counts()
        plt.figure(figsize=(12, 6))
        author_counts.plot(kind='bar', color='lightcoral')
        plt.title('å„ä½œè€…æ¨¡å‹æ•°é‡')
        plt.xlabel('ä½œè€…')
        plt.ylabel('æ¨¡å‹æ•°é‡')
        plt.xticks(rotation=45, ha='right')
        plt.tight_layout()
        plt.savefig(output_path / 'author_model_counts.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        # 3. æ¨¡å‹ç±»å‹åˆ†å¸ƒ
        type_counts = self.df['type'].value_counts()
        plt.figure(figsize=(8, 8))
        plt.pie(type_counts.values, labels=type_counts.index, autopct='%1.1f%%', startangle=90)
        plt.title('æ¨¡å‹ç±»å‹åˆ†å¸ƒ')
        plt.axis('equal')
        plt.savefig(output_path / 'model_type_distribution.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        logger.info(f"å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜åˆ°: {output_path}")
    
    def generate_report(self, output_dir: str = "data/processed/mcp_analysis") -> str:
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        if self.df is None:
            return "æ²¡æœ‰æ•°æ®å¯ä»¥åˆ†æ"
            
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        # æ‰§è¡Œå„é¡¹åˆ†æ
        download_analysis = self.analyze_downloads()
        author_analysis = self.analyze_authors()
        type_analysis = self.analyze_model_types()
        
        # ç”ŸæˆæŠ¥å‘Š
        report = f"""# Liblibæ±½è½¦äº¤é€šæ¨¡å‹æ•°æ®åˆ†ææŠ¥å‘Š

## ğŸ“Š æ•°æ®æ¦‚è§ˆ
- **é‡‡é›†æ—¶é—´**: {self.df['collected_at'].iloc[0][:19]}
- **æ€»æ¨¡å‹æ•°**: {len(self.df)}
- **æ•°æ®æ¥æº**: MCPæµè§ˆå™¨è§‚å¯Ÿ

## ğŸ“ˆ ä¸‹è½½é‡åˆ†æ
- **æ€»ä¸‹è½½é‡**: {download_analysis.get('total_downloads', 0):,}
- **å¹³å‡ä¸‹è½½é‡**: {download_analysis.get('avg_downloads', 0):,}
- **æœ€é«˜ä¸‹è½½é‡**: {download_analysis.get('max_downloads', 0):,}
- **æœ€ä½ä¸‹è½½é‡**: {download_analysis.get('min_downloads', 0):,}

## ğŸ‘¥ ä½œè€…åˆ†æ
- **æ€»ä½œè€…æ•°**: {author_analysis.get('total_authors', 0)}
- **æœ€å¤šæ¨¡å‹ä½œè€…**: {list(author_analysis.get('top_authors_by_models', {}).keys())[:3] if author_analysis.get('top_authors_by_models') else []}

## ğŸ·ï¸ æ¨¡å‹ç±»å‹åˆ†æ
- **æ¨¡å‹ç±»å‹**: {list(type_analysis.get('type_distribution', {}).keys())}
- **ç‰ˆæœ¬åˆ†å¸ƒ**: {type_analysis.get('version_distribution', {})}

## ğŸ“‹ è¯¦ç»†æ•°æ®
"""
        
        # æ·»åŠ æ¨¡å‹åˆ—è¡¨
        for i, row in self.df.iterrows():
            report += f"""
### {row['title']}
- **ç±»å‹**: {row['type']} {row['version']}
- **ä½œè€…**: {row['author']}
- **ä¸‹è½½é‡**: {row['downloads']}
- **ç‚¹èµæ•°**: {row['likes']}
- **æ”¶è—æ•°**: {row['collections']}
- **ä¸“å±**: {'æ˜¯' if row['exclusive'] else 'å¦'}
"""
        
        # ä¿å­˜æŠ¥å‘Š
        report_path = output_path / 'analysis_report.md'
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report)
            
        logger.info(f"åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")
        return str(report_path)
    
    def run_full_analysis(self) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´åˆ†æ"""
        logger.info("å¼€å§‹è¿è¡Œå®Œæ•´æ•°æ®åˆ†æ...")
        
        if not self.load_latest_data():
            return {}
            
        # æ‰§è¡Œå„é¡¹åˆ†æ
        results = {
            'download_analysis': self.analyze_downloads(),
            'author_analysis': self.analyze_authors(),
            'type_analysis': self.analyze_model_types(),
            'total_models': len(self.df)
        }
        
        # ç”Ÿæˆå¯è§†åŒ–
        self.generate_visualizations()
        
        # ç”ŸæˆæŠ¥å‘Š
        report_path = self.generate_report()
        results['report_path'] = report_path
        
        logger.info("æ•°æ®åˆ†æå®Œæˆï¼")
        return results

def main():
    """ä¸»å‡½æ•°"""
    analyzer = MCPDataAnalyzer()
    results = analyzer.run_full_analysis()
    
    if results:
        print("\nâœ… æ•°æ®åˆ†æå®Œæˆï¼")
        print(f"ğŸ“Š æ€»æ¨¡å‹æ•°: {results['total_models']}")
        print(f"ğŸ“ˆ æ€»ä¸‹è½½é‡: {results['download_analysis'].get('total_downloads', 0):,}")
        print(f"ğŸ‘¥ æ€»ä½œè€…æ•°: {results['author_analysis'].get('total_authors', 0)}")
        print(f"ğŸ“„ æŠ¥å‘Šæ–‡ä»¶: {results['report_path']}")
    else:
        print("âŒ æ•°æ®åˆ†æå¤±è´¥")

if __name__ == "__main__":
    main()
