#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ€§èƒ½æµ‹è¯•è„šæœ¬
æµ‹è¯•å¹¶å‘æ€§èƒ½ã€å‹åŠ›æµ‹è¯•ã€æ€§èƒ½åŸºå‡†ç­‰
"""

import os
import sys
import time
import json
import asyncio
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime
import statistics
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "src"))

def test_config_manager_performance():
    """æµ‹è¯•é…ç½®ç®¡ç†å™¨çš„æ€§èƒ½"""
    print("\nğŸ” æµ‹è¯•é…ç½®ç®¡ç†å™¨æ€§èƒ½")
    print("=" * 50)
    
    try:
        from config_manager import ConfigManager
        
        # æµ‹è¯•é…ç½®åŠ è½½æ€§èƒ½
        start_time = time.time()
        config_manager = ConfigManager()
        config = config_manager.load_config()
        load_time = time.time() - start_time
        
        print(f"âœ… é…ç½®åŠ è½½è€—æ—¶: {load_time:.4f} ç§’")
        
        # æµ‹è¯•é…ç½®è·å–æ€§èƒ½
        iterations = 1000
        start_time = time.time()
        for _ in range(iterations):
            _ = config_manager.get("api_base")
            _ = config_manager.get("max_workers")
            _ = config_manager.get("timeout")
        get_time = time.time() - start_time
        
        print(f"âœ… é…ç½®è·å–æ€§èƒ½: {iterations} æ¬¡æ“ä½œè€—æ—¶ {get_time:.4f} ç§’")
        print(f"âœ… å¹³å‡æ¯æ¬¡æ“ä½œ: {get_time/iterations*1000:.2f} æ¯«ç§’")
        
        return True
        
    except Exception as e:
        print(f"âŒ é…ç½®ç®¡ç†å™¨æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_mcp_collector_performance():
    """æµ‹è¯•MCPé‡‡é›†å™¨çš„æ€§èƒ½"""
    print("\nğŸ” æµ‹è¯•MCPé‡‡é›†å™¨æ€§èƒ½")
    print("=" * 50)
    
    try:
        from scraping.liblib_mcp_collector import LiblibMCPCollector
        
        # æµ‹è¯•æ•°æ®æ”¶é›†æ€§èƒ½
        start_time = time.time()
        collector = LiblibMCPCollector()
        models = collector.collect_models()
        collect_time = time.time() - start_time
        
        print(f"âœ… æ•°æ®æ”¶é›†è€—æ—¶: {collect_time:.4f} ç§’")
        print(f"âœ… æ”¶é›†åˆ° {len(models)} ä¸ªæ¨¡å‹")
        
        # æµ‹è¯•æ•°æ®ä¿å­˜æ€§èƒ½
        start_time = time.time()
        json_path, csv_path = collector.save_models(models)
        save_time = time.time() - start_time
        
        print(f"âœ… æ•°æ®ä¿å­˜è€—æ—¶: {save_time:.4f} ç§’")
        
        # æµ‹è¯•æ‘˜è¦ç”Ÿæˆæ€§èƒ½
        start_time = time.time()
        summary_path = collector.generate_summary(models)
        summary_time = time.time() - start_time
        
        print(f"âœ… æ‘˜è¦ç”Ÿæˆè€—æ—¶: {summary_time:.4f} ç§’")
        
        total_time = collect_time + save_time + summary_time
        print(f"âœ… æ€»è€—æ—¶: {total_time:.4f} ç§’")
        
        return True
        
    except Exception as e:
        print(f"âŒ MCPé‡‡é›†å™¨æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_concurrent_collection():
    """æµ‹è¯•å¹¶å‘é‡‡é›†æ€§èƒ½"""
    print("\nğŸ” æµ‹è¯•å¹¶å‘é‡‡é›†æ€§èƒ½")
    print("=" * 50)
    
    try:
        from scraping.liblib_api_sampler import create_session, safe_post, default_list_payload
        
        # åˆ›å»ºä¼šè¯
        session = create_session()
        api_url = "https://api2.liblib.art/api/www/model/list"
        
        # æµ‹è¯•ä¸åŒå¹¶å‘æ•°çš„æ€§èƒ½
        concurrency_levels = [1, 2, 4, 8]
        results = {}
        
        for concurrency in concurrency_levels:
            print(f"ğŸ”„ æµ‹è¯•å¹¶å‘æ•°: {concurrency}")
            
            start_time = time.time()
            
            # ä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡Œå¹¶å‘è¯·æ±‚
            with ThreadPoolExecutor(max_workers=concurrency) as executor:
                futures = []
                for i in range(concurrency):
                    payload = default_list_payload(page=i+1, page_size=5)
                    future = executor.submit(safe_post, session, api_url, payload, 10)
                    futures.append(future)
                
                # ç­‰å¾…æ‰€æœ‰è¯·æ±‚å®Œæˆ
                responses = []
                for future in as_completed(futures):
                    try:
                        response = future.result()
                        if response and response.status_code == 200:
                            responses.append(response)
                    except Exception as e:
                        print(f"âš ï¸  å¹¶å‘è¯·æ±‚å¼‚å¸¸: {e}")
            
            end_time = time.time()
            duration = end_time - start_time
            
            results[concurrency] = {
                'duration': duration,
                'success_count': len(responses),
                'throughput': len(responses) / duration if duration > 0 else 0
            }
            
            print(f"âœ… å¹¶å‘æ•° {concurrency}: è€—æ—¶ {duration:.4f}s, æˆåŠŸ {len(responses)}/{concurrency}")
        
        # åˆ†ææ€§èƒ½ç»“æœ
        print(f"\nğŸ“Š å¹¶å‘æ€§èƒ½åˆ†æ:")
        for concurrency, result in results.items():
            print(f"   å¹¶å‘æ•° {concurrency}: ååé‡ {result['throughput']:.2f} è¯·æ±‚/ç§’")
        
        return True
        
    except Exception as e:
        print(f"âŒ å¹¶å‘é‡‡é›†æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_database_performance():
    """æµ‹è¯•æ•°æ®åº“æ€§èƒ½"""
    print("\nğŸ” æµ‹è¯•æ•°æ®åº“æ€§èƒ½")
    print("=" * 50)
    
    try:
        from database.database_manager import DatabaseManager
        
        # åˆ›å»ºæ•°æ®åº“ç®¡ç†å™¨
        db_manager = DatabaseManager()
        
        # æµ‹è¯•è¿æ¥æ€§èƒ½
        start_time = time.time()
        connection = db_manager.get_connection()
        connect_time = time.time() - start_time
        
        print(f"âœ… æ•°æ®åº“è¿æ¥è€—æ—¶: {connect_time:.4f} ç§’")
        
        if connection:
            # æµ‹è¯•æŸ¥è¯¢æ€§èƒ½
            test_query = "SELECT 1 as test"
            start_time = time.time()
            
            try:
                cursor = connection.cursor()
                cursor.execute(test_query)
                result = cursor.fetchone()
                cursor.close()
                
                query_time = time.time() - start_time
                print(f"âœ… åŸºç¡€æŸ¥è¯¢è€—æ—¶: {query_time:.4f} ç§’")
                
                # æµ‹è¯•æ‰¹é‡æ’å…¥æ€§èƒ½ï¼ˆæ¨¡æ‹Ÿï¼‰
                print(f"âœ… æ•°æ®åº“æ€§èƒ½æµ‹è¯•å®Œæˆ")
                
            except Exception as e:
                print(f"âš ï¸  æŸ¥è¯¢æµ‹è¯•å¼‚å¸¸: {e}")
            
            connection.close()
        
        return True
        
    except Exception as e:
        print(f"âŒ æ•°æ®åº“æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_analysis_performance():
    """æµ‹è¯•åˆ†æåŠŸèƒ½æ€§èƒ½"""
    print("\nğŸ” æµ‹è¯•åˆ†æåŠŸèƒ½æ€§èƒ½")
    print("=" * 50)
    
    try:
        from analysis.car_design_trend_analyzer import CarDesignTrendAnalyzer
        
        # åˆ›å»ºåˆ†æå™¨
        analyzer = CarDesignTrendAnalyzer()
        
        # æµ‹è¯•é…ç½®åŠ è½½æ€§èƒ½
        start_time = time.time()
        config = analyzer.load_config()
        config_time = time.time() - start_time
        
        print(f"âœ… é…ç½®åŠ è½½è€—æ—¶: {config_time:.4f} ç§’")
        
        # æµ‹è¯•æ•°æ®åŠ è½½æ€§èƒ½ï¼ˆæ¨¡æ‹Ÿï¼‰
        start_time = time.time()
        # è¿™é‡Œåº”è¯¥åŠ è½½æµ‹è¯•æ•°æ®
        data_load_time = time.time() - start_time
        
        print(f"âœ… æ•°æ®åŠ è½½è€—æ—¶: {data_load_time:.4f} ç§’")
        
        # æµ‹è¯•åˆ†ææ€§èƒ½ï¼ˆæ¨¡æ‹Ÿï¼‰
        start_time = time.time()
        # è¿™é‡Œåº”è¯¥æ‰§è¡Œåˆ†æé€»è¾‘
        analysis_time = time.time() - start_time
        
        print(f"âœ… åˆ†æå¤„ç†è€—æ—¶: {analysis_time:.4f} ç§’")
        
        total_time = config_time + data_load_time + analysis_time
        print(f"âœ… æ€»è€—æ—¶: {total_time:.4f} ç§’")
        
        return True
        
    except Exception as e:
        print(f"âŒ åˆ†æåŠŸèƒ½æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_memory_usage():
    """æµ‹è¯•å†…å­˜ä½¿ç”¨æƒ…å†µ"""
    print("\nğŸ” æµ‹è¯•å†…å­˜ä½¿ç”¨æƒ…å†µ")
    print("=" * 50)
    
    try:
        import psutil
        import os
        
        # è·å–å½“å‰è¿›ç¨‹
        process = psutil.Process(os.getpid())
        
        # æµ‹è¯•å‰å†…å­˜ä½¿ç”¨
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB
        print(f"âœ… åˆå§‹å†…å­˜ä½¿ç”¨: {initial_memory:.2f} MB")
        
        # æ¨¡æ‹Ÿå¤§é‡æ•°æ®å¤„ç†
        large_data = []
        for i in range(10000):
            large_data.append({
                'id': i,
                'title': f'Test Model {i}',
                'type': 'car',
                'author': f'Author {i % 100}',
                'category': f'Category {i % 10}'
            })
        
        # æµ‹è¯•åå†…å­˜ä½¿ç”¨
        final_memory = process.memory_info().rss / 1024 / 1024  # MB
        memory_increase = final_memory - initial_memory
        
        print(f"âœ… æœ€ç»ˆå†…å­˜ä½¿ç”¨: {final_memory:.2f} MB")
        print(f"âœ… å†…å­˜å¢é•¿: {memory_increase:.2f} MB")
        
        # æ¸…ç†æ•°æ®
        del large_data
        
        # æ¸…ç†åå†…å­˜ä½¿ç”¨
        cleanup_memory = process.memory_info().rss / 1024 / 1024  # MB
        print(f"âœ… æ¸…ç†åå†…å­˜: {cleanup_memory:.2f} MB")
        
        return True
        
    except ImportError:
        print("âš ï¸  psutilæœªå®‰è£…ï¼Œè·³è¿‡å†…å­˜æµ‹è¯•")
        return True
    except Exception as e:
        print(f"âŒ å†…å­˜ä½¿ç”¨æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_network_latency():
    """æµ‹è¯•ç½‘ç»œå»¶è¿Ÿ"""
    print("\nğŸ” æµ‹è¯•ç½‘ç»œå»¶è¿Ÿ")
    print("=" * 50)
    
    try:
        import requests
        import statistics
        
        # æµ‹è¯•ç›®æ ‡URL
        test_urls = [
            "https://api2.liblib.art",
            "https://www.liblib.art",
            "https://httpbin.org/delay/1"
        ]
        
        latency_results = {}
        
        for url in test_urls:
            print(f"ğŸ”„ æµ‹è¯•URL: {url}")
            latencies = []
            
            # æ‰§è¡Œå¤šæ¬¡è¯·æ±‚æµ‹è¯•å»¶è¿Ÿ
            for i in range(5):
                try:
                    start_time = time.time()
                    response = requests.get(url, timeout=10)
                    end_time = time.time()
                    
                    if response.status_code == 200:
                        latency = (end_time - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
                        latencies.append(latency)
                        print(f"   è¯·æ±‚ {i+1}: {latency:.2f}ms")
                    else:
                        print(f"   è¯·æ±‚ {i+1}: çŠ¶æ€ç  {response.status_code}")
                        
                except Exception as e:
                    print(f"   è¯·æ±‚ {i+1}: å¼‚å¸¸ {e}")
            
            if latencies:
                avg_latency = statistics.mean(latencies)
                min_latency = min(latencies)
                max_latency = max(latencies)
                
                latency_results[url] = {
                    'average': avg_latency,
                    'min': min_latency,
                    'max': max_latency
                }
                
                print(f"âœ… {url}: å¹³å‡å»¶è¿Ÿ {avg_latency:.2f}ms (æœ€å°: {min_latency:.2f}ms, æœ€å¤§: {max_latency:.2f}ms)")
        
        # åˆ†æç½‘ç»œæ€§èƒ½
        if latency_results:
            all_latencies = [result['average'] for result in latency_results.values()]
            overall_avg = statistics.mean(all_latencies)
            print(f"\nğŸ“Š æ•´ä½“ç½‘ç»œæ€§èƒ½: å¹³å‡å»¶è¿Ÿ {overall_avg:.2f}ms")
        
        return True
        
    except Exception as e:
        print(f"âŒ ç½‘ç»œå»¶è¿Ÿæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_file_io_performance():
    """æµ‹è¯•æ–‡ä»¶I/Oæ€§èƒ½"""
    print("\nğŸ” æµ‹è¯•æ–‡ä»¶I/Oæ€§èƒ½")
    print("=" * 50)
    
    try:
        import tempfile
        import json
        
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as temp_file:
            temp_path = temp_file.name
        
        try:
            # æµ‹è¯•å†™å…¥æ€§èƒ½
            test_data = []
            for i in range(1000):
                test_data.append({
                    'id': i,
                    'title': f'Test Model {i}',
                    'type': 'car',
                    'author': f'Author {i % 100}',
                    'category': f'Category {i % 10}',
                    'description': f'This is a test description for model {i} with some additional text to make it longer.'
                })
            
            # JSONå†™å…¥æµ‹è¯•
            start_time = time.time()
            with open(temp_path, 'w', encoding='utf-8') as f:
                json.dump(test_data, f, ensure_ascii=False, indent=2)
            write_time = time.time() - start_time
            
            print(f"âœ… JSONå†™å…¥è€—æ—¶: {write_time:.4f} ç§’")
            print(f"âœ… å†™å…¥é€Ÿåº¦: {len(test_data)/write_time:.0f} æ¡è®°å½•/ç§’")
            
            # JSONè¯»å–æµ‹è¯•
            start_time = time.time()
            with open(temp_path, 'r', encoding='utf-8') as f:
                loaded_data = json.load(f)
            read_time = time.time() - start_time
            
            print(f"âœ… JSONè¯»å–è€—æ—¶: {read_time:.4f} ç§’")
            print(f"âœ… è¯»å–é€Ÿåº¦: {len(loaded_data)/read_time:.0f} æ¡è®°å½•/ç§’")
            
            # éªŒè¯æ•°æ®å®Œæ•´æ€§
            if len(loaded_data) == len(test_data):
                print(f"âœ… æ•°æ®å®Œæ•´æ€§éªŒè¯é€šè¿‡: {len(loaded_data)} æ¡è®°å½•")
            else:
                print(f"âŒ æ•°æ®å®Œæ•´æ€§éªŒè¯å¤±è´¥: æœŸæœ› {len(test_data)}, å®é™… {len(loaded_data)}")
                return False
            
            return True
            
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(temp_path):
                os.unlink(temp_path)
        
    except Exception as e:
        print(f"âŒ æ–‡ä»¶I/Oæ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False

def run_performance_benchmark():
    """è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•"""
    print("ğŸš€ å¼€å§‹è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•")
    print("=" * 80)
    
    test_functions = [
        test_config_manager_performance,
        test_mcp_collector_performance,
        test_concurrent_collection,
        test_database_performance,
        test_analysis_performance,
        test_memory_usage,
        test_network_latency,
        test_file_io_performance
    ]
    
    passed = 0
    failed = 0
    start_time = time.time()
    
    for test_func in test_functions:
        try:
            if test_func():
                passed += 1
            else:
                failed += 1
        except Exception as e:
            print(f"âŒ æµ‹è¯• {test_func.__name__} æ‰§è¡Œå¼‚å¸¸: {e}")
            failed += 1
    
    total_time = time.time() - start_time
    
    print("\n" + "=" * 80)
    print(f"ğŸ“Š æ€§èƒ½æµ‹è¯•ç»“æœæ±‡æ€»")
    print(f"âœ… é€šè¿‡: {passed}")
    print(f"âŒ å¤±è´¥: {failed}")
    print(f"ğŸ“ˆ æˆåŠŸç‡: {passed/(passed+failed)*100:.1f}%")
    print(f"â±ï¸  æ€»è€—æ—¶: {total_time:.2f} ç§’")
    
    return passed, failed

if __name__ == "__main__":
    run_performance_benchmark()
