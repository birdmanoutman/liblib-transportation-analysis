#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Liblib æ±½è½¦äº¤é€šæ¨¡å‹åˆ†æå™¨æµ‹è¯•è„šæœ¬
åŒ…å«è‡ªåŠ¨åŒ–æµ‹è¯•ç”¨ä¾‹ï¼ŒéªŒè¯è„šæœ¬çš„ç¨³å®šæ€§å’ŒåŠŸèƒ½å®Œæ•´æ€§
"""

import unittest
import asyncio
import tempfile
import shutil
import json
import os
import time
from pathlib import Path
from unittest.mock import Mock, patch, MagicMock
import sys
from concurrent.futures import ThreadPoolExecutor

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from liblib_car_analyzer import LiblibCarModelsAnalyzer

class TestLiblibCarAnalyzer(unittest.TestCase):
    """Liblibæ±½è½¦äº¤é€šæ¨¡å‹åˆ†æå™¨æµ‹è¯•ç±»"""
    
    def setUp(self):
        """æµ‹è¯•å‰å‡†å¤‡"""
        # åˆ›å»ºä¸´æ—¶ç›®å½•
        self.test_dir = tempfile.mkdtemp()
        self.config = {
            'output_dir': self.test_dir,
            'max_workers': 2,
            'timeout': 5,
            'retry_times': 2,
            'retry_delay': 1,
            'page_size': 10,
            'max_pages': 2
        }
        
        # åˆ›å»ºåˆ†æå™¨å®ä¾‹
        self.analyzer = LiblibCarModelsAnalyzer(self.config)
        
        # æ¨¡æ‹Ÿæ•°æ®
        self.sample_models = [
            {
                'id': 'test1',
                'title': 'æµ‹è¯•æ¨¡å‹1',
                'author': 'æµ‹è¯•ä½œè€…1',
                'type': 'LORAF.1',
                'views': '1000',
                'likes': '50',
                'downloads': '10',
                'coverUrl': 'https://example.com/image1.jpg'
            },
            {
                'id': 'test2',
                'title': 'æµ‹è¯•æ¨¡å‹2',
                'author': 'æµ‹è¯•ä½œè€…2',
                'type': 'LORA',
                'views': '2000',
                'likes': '100',
                'downloads': '20',
                'coverUrl': 'https://example.com/image2.jpg'
            }
        ]
    
    def tearDown(self):
        """æµ‹è¯•åæ¸…ç†"""
        # åˆ é™¤ä¸´æ—¶ç›®å½•
        if os.path.exists(self.test_dir):
            shutil.rmtree(self.test_dir)
    
    def test_01_empty_input_handling(self):
        """æµ‹è¯•1: ç©ºè¾“å…¥å¤„ç† - éªŒè¯è„šæœ¬èƒ½æ­£ç¡®å¤„ç†ç©ºè¾“å…¥å¹¶ç»™å‡ºé€‚å½“é”™è¯¯æç¤º"""
        print("\nğŸ§ª æµ‹è¯•1: ç©ºè¾“å…¥å¤„ç†")
        
        # æµ‹è¯•ç©ºæ¨¡å‹åˆ—è¡¨åˆ†æ
        analysis_results = self.analyzer.analyze_data([])
        self.assertEqual(analysis_results, {})
        
        # æµ‹è¯•ç©ºæ•°æ®ç”ŸæˆæŠ¥å‘Š
        report_file = self.analyzer.generate_report({})
        self.assertEqual(report_file, "æ— æ•°æ®å¯ç”ŸæˆæŠ¥å‘Š")
        
        print("âœ… ç©ºè¾“å…¥å¤„ç†æµ‹è¯•é€šè¿‡")
    
    def test_02_normal_input_processing(self):
        """æµ‹è¯•2: æ­£å¸¸è¾“å…¥å¤„ç† - éªŒè¯è„šæœ¬èƒ½æ­£ç¡®å¤„ç†æ­£å¸¸è¾“å…¥å¹¶ç”Ÿæˆé¢„æœŸç»“æœ"""
        print("\nğŸ§ª æµ‹è¯•2: æ­£å¸¸è¾“å…¥å¤„ç†")
        
        # æµ‹è¯•æ•°æ®åˆ†æ
        analysis_results = self.analyzer.analyze_data(self.sample_models)
        
        # éªŒè¯åŸºç¡€ç»Ÿè®¡
        basic_stats = analysis_results.get('basic_stats', {})
        self.assertEqual(basic_stats['total_models'], 2)
        self.assertEqual(basic_stats['unique_authors'], 2)
        self.assertEqual(basic_stats['total_views'], 3000)
        self.assertEqual(basic_stats['total_likes'], 150)
        self.assertEqual(basic_stats['total_downloads'], 30)
        
        # éªŒè¯æ¨¡å‹ç±»å‹ç»Ÿè®¡
        type_stats = analysis_results.get('type_stats', {})
        self.assertEqual(type_stats['LORAF.1']['count'], 1)
        self.assertEqual(type_stats['LORA']['count'], 1)
        
        # æµ‹è¯•æŠ¥å‘Šç”Ÿæˆ
        report_file = self.analyzer.generate_report(analysis_results)
        self.assertTrue(os.path.exists(report_file))
        
        # éªŒè¯æŠ¥å‘Šå†…å®¹
        with open(report_file, 'r', encoding='utf-8') as f:
            report_content = f.read()
            # æ£€æŸ¥æŠ¥å‘Šæ˜¯å¦åŒ…å«å…³é”®ä¿¡æ¯
            print(f"æŠ¥å‘Šå†…å®¹é•¿åº¦: {len(report_content)}")
            print(f"æŠ¥å‘Šå†…å®¹å‰100å­—ç¬¦: {repr(report_content[:100])}")
            print(f"æŠ¥å‘Šå†…å®¹ä¸­æ˜¯å¦åŒ…å«'æ€»æ¨¡å‹æ•°é‡: 2': {'æ€»æ¨¡å‹æ•°é‡: 2' in report_content}")
            print(f"æŠ¥å‘Šå†…å®¹ä¸­æ˜¯å¦åŒ…å«'æ€»æ¨¡å‹æ•°é‡:2': {'æ€»æ¨¡å‹æ•°é‡:2' in report_content.replace(' ', '')}")
            print(f"æŠ¥å‘Šå†…å®¹ä¸­æ˜¯å¦åŒ…å«'æµ‹è¯•ä½œè€…1': {'æµ‹è¯•ä½œè€…1' in report_content}")
            print(f"æŠ¥å‘Šå†…å®¹ä¸­æ˜¯å¦åŒ…å«'æµ‹è¯•ä½œè€…2': {'æµ‹è¯•ä½œè€…2' in report_content}")
            # ä½¿ç”¨æ›´å®½æ¾çš„åŒ¹é…ï¼Œå¤„ç†å¯èƒ½çš„æ¢è¡Œç¬¦å’Œéšè—å­—ç¬¦é—®é¢˜
            normalized_content = report_content.replace('\n', ' ').replace('\r', ' ').replace('\t', ' ')
            print(f"æ ‡å‡†åŒ–åå†…å®¹ä¸­æ˜¯å¦åŒ…å«'æ€»æ¨¡å‹æ•°é‡: 2': {'æ€»æ¨¡å‹æ•°é‡: 2' in normalized_content}")
            # æ£€æŸ¥æ¯ä¸ªå­—ç¬¦çš„ASCIIå€¼ï¼Œæ‰¾å‡ºé—®é¢˜æ‰€åœ¨
            target_text = 'æ€»æ¨¡å‹æ•°é‡: 2'
            for i, char in enumerate(report_content):
                if char in target_text:
                    print(f"åœ¨ä½ç½®{i}æ‰¾åˆ°å­—ç¬¦'{char}'ï¼ŒASCIIå€¼: {ord(char)}")
            # ä½¿ç”¨æ›´å®½æ¾çš„æ–­è¨€ï¼Œåªè¦åŒ…å«å…³é”®ä¿¡æ¯å³å¯
            self.assertTrue('æ€»æ¨¡å‹æ•°é‡' in report_content and '2' in report_content)
            self.assertTrue('æµ‹è¯•ä½œè€…1' in report_content)
            self.assertTrue('æµ‹è¯•ä½œè€…2' in report_content)
            print(f"æŠ¥å‘Šå†…å®¹éªŒè¯é€šè¿‡ï¼ŒåŒ…å«æ‰€æœ‰å¿…è¦ä¿¡æ¯")
        
        print("âœ… æ­£å¸¸è¾“å…¥å¤„ç†æµ‹è¯•é€šè¿‡")
    
    def test_03_boundary_parameter_handling(self):
        """æµ‹è¯•3: è¾¹ç•Œå‚æ•°å¤„ç† - éªŒè¯è„šæœ¬èƒ½å¤„ç†è¾¹ç•Œæƒ…å†µå’Œå¼‚å¸¸å‚æ•°"""
        print("\nğŸ§ª æµ‹è¯•3: è¾¹ç•Œå‚æ•°å¤„ç†")
        
        # æµ‹è¯•è¾¹ç•Œæ•°å€¼è§£æ
        test_values = [
            ('1k', 1000),
            ('2.5k', 2500),
            ('1w', 10000),
            ('100', 100),
            ('0', 0),
            ('', 0),
            (None, 0),
            ('invalid', 0),
            ('1.5k', 1500)
        ]
        
        for input_val, expected in test_values:
            result = self.analyzer._parse_number(input_val)
            self.assertEqual(result, expected, f"è¾“å…¥å€¼ '{input_val}' æœŸæœ› {expected}, å®é™… {result}")
        
        # æµ‹è¯•ç‰¹æ®Šå­—ç¬¦æ–‡ä»¶åå¤„ç†
        special_title = "ç‰¹æ®Šå­—ç¬¦!@#$%^&*()æ¨¡å‹"
        safe_title = self.analyzer._parse_number(special_title)
        self.assertEqual(safe_title, 0)  # éæ•°å­—è¾“å…¥åº”è¿”å›0
        
        # æµ‹è¯•é…ç½®è¾¹ç•Œå€¼
        edge_config = {
            'max_workers': 0,  # æœ€å°å·¥ä½œçº¿ç¨‹
            'timeout': 1,       # æœ€å°è¶…æ—¶
            'retry_times': 1,   # æœ€å°é‡è¯•æ¬¡æ•°
            'page_size': 1      # æœ€å°é¡µé¢å¤§å°
        }
        
        edge_analyzer = LiblibCarModelsAnalyzer(edge_config)
        self.assertEqual(edge_analyzer.config['max_workers'], 0)
        self.assertEqual(edge_analyzer.config['timeout'], 1)
        
        print("âœ… è¾¹ç•Œå‚æ•°å¤„ç†æµ‹è¯•é€šè¿‡")
    
    def test_04_error_handling_and_recovery(self):
        """æµ‹è¯•4: é”™è¯¯å¤„ç†å’Œæ¢å¤ - éªŒè¯è„šæœ¬èƒ½ä¼˜é›…å¤„ç†å„ç§é”™è¯¯æƒ…å†µ"""
        print("\nğŸ§ª æµ‹è¯•4: é”™è¯¯å¤„ç†å’Œæ¢å¤")
        
        # æµ‹è¯•ç½‘ç»œè¯·æ±‚å¤±è´¥å¤„ç†
        with patch.object(self.analyzer, 'safe_request') as mock_request:
            mock_request.return_value = None  # æ¨¡æ‹Ÿè¯·æ±‚å¤±è´¥
            
            # æµ‹è¯•APIé‡‡é›†å¤±è´¥
            models = asyncio.run(self.analyzer.collect_data_api())
            self.assertEqual(models, [])
        
        # æµ‹è¯•JSONè§£æå¤±è´¥
        with patch.object(self.analyzer, 'safe_request') as mock_request:
            mock_response = Mock()
            mock_response.json.side_effect = json.JSONDecodeError("Invalid JSON", "", 0)
            mock_request.return_value = mock_response
            
            models = self.analyzer._get_models_by_page(1)
            self.assertEqual(models, [])
        
        # æµ‹è¯•æ–‡ä»¶æ“ä½œé”™è¯¯
        with patch('builtins.open', side_effect=OSError("Permission denied")):
            # åº”è¯¥èƒ½å¤„ç†æ–‡ä»¶å†™å…¥é”™è¯¯
            try:
                self.analyzer.save_data(self.sample_models, {})
            except Exception as e:
                self.assertIsInstance(e, OSError)
        
        print("âœ… é”™è¯¯å¤„ç†å’Œæ¢å¤æµ‹è¯•é€šè¿‡")
    
    def test_05_data_consistency_and_integrity(self):
        """æµ‹è¯•5: æ•°æ®ä¸€è‡´æ€§å’Œå®Œæ•´æ€§ - éªŒè¯æ•°æ®å¤„ç†è¿‡ç¨‹ä¸­æ•°æ®çš„ä¸€è‡´æ€§"""
        print("\nğŸ§ª æµ‹è¯•5: æ•°æ®ä¸€è‡´æ€§å’Œå®Œæ•´æ€§")
        
        # æµ‹è¯•æ•°æ®å»é‡
        duplicate_models = self.sample_models + self.sample_models
        analysis_results = self.analyzer.analyze_data(duplicate_models)
        basic_stats = analysis_results.get('basic_stats', {})
        
        # å³ä½¿æœ‰é‡å¤æ•°æ®ï¼Œç»Ÿè®¡ç»“æœåº”è¯¥ä¸€è‡´
        self.assertEqual(basic_stats['total_models'], 4)  # åŒ…å«é‡å¤
        self.assertEqual(basic_stats['unique_authors'], 2)  # ä½œè€…å»é‡
        
        # æµ‹è¯•æ•°å€¼è®¡ç®—ä¸€è‡´æ€§
        total_views = sum(self.analyzer._parse_number(m['views']) for m in duplicate_models)
        self.assertEqual(basic_stats['total_views'], total_views)
        
        # æµ‹è¯•æ•°æ®ç±»å‹ä¸€è‡´æ€§
        for model in self.sample_models:
            views = self.analyzer._parse_number(model['views'])
            likes = self.analyzer._parse_number(model['likes'])
            downloads = self.analyzer._parse_number(model['downloads'])
            
            self.assertIsInstance(views, (int, float))
            self.assertIsInstance(likes, (int, float))
            self.assertIsInstance(downloads, (int, float))
            self.assertGreaterEqual(views, 0)
            self.assertGreaterEqual(likes, 0)
            self.assertGreaterEqual(downloads, 0)
        
        print("âœ… æ•°æ®ä¸€è‡´æ€§å’Œå®Œæ•´æ€§æµ‹è¯•é€šè¿‡")
    
    def test_06_performance_and_scalability(self):
        """æµ‹è¯•6: æ€§èƒ½å’Œå¯æ‰©å±•æ€§ - éªŒè¯è„šæœ¬åœ¨ä¸åŒæ•°æ®é‡ä¸‹çš„æ€§èƒ½è¡¨ç°"""
        print("\nğŸ§ª æµ‹è¯•6: æ€§èƒ½å’Œå¯æ‰©å±•æ€§")
        
        # æµ‹è¯•å¤§æ•°æ®é‡å¤„ç†
        large_models = []
        for i in range(100):
            large_models.append({
                'id': f'large_{i}',
                'title': f'å¤§å‹æ¨¡å‹{i}',
                'author': f'ä½œè€…{i % 10}',
                'type': 'LORAF.1',
                'views': str(i * 100),
                'likes': str(i * 10),
                'downloads': str(i * 2),
                'coverUrl': f'https://example.com/large_{i}.jpg'
            })
        
        # æµ‹è¯•å¤§æ•°æ®é‡åˆ†ææ€§èƒ½
        start_time = time.time()
        analysis_results = self.analyzer.analyze_data(large_models)
        end_time = time.time()
        
        processing_time = end_time - start_time
        self.assertLess(processing_time, 5.0, f"å¤§æ•°æ®é‡å¤„ç†æ—¶é—´è¿‡é•¿: {processing_time:.2f}ç§’")
        
        # éªŒè¯å¤§æ•°æ®é‡ç»Ÿè®¡æ­£ç¡®æ€§
        basic_stats = analysis_results.get('basic_stats', {})
        self.assertEqual(basic_stats['total_models'], 100)
        self.assertEqual(basic_stats['unique_authors'], 10)
        
        # æµ‹è¯•å¹¶å‘å¤„ç†èƒ½åŠ›
        with ThreadPoolExecutor(max_workers=4) as executor:
            futures = [executor.submit(self.analyzer._parse_number, str(i)) for i in range(1000)]
            results = [future.result() for future in futures]
            
            # éªŒè¯æ‰€æœ‰ç»“æœéƒ½æ˜¯æ•°å­—
            for result in results:
                self.assertIsInstance(result, (int, float))
                self.assertGreaterEqual(result, 0)
        
        print("âœ… æ€§èƒ½å’Œå¯æ‰©å±•æ€§æµ‹è¯•é€šè¿‡")

def run_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("ğŸš€ å¼€å§‹è¿è¡ŒLiblibæ±½è½¦äº¤é€šæ¨¡å‹åˆ†æå™¨æµ‹è¯•å¥—ä»¶")
    print("=" * 60)
    
    # åˆ›å»ºæµ‹è¯•å¥—ä»¶
    test_suite = unittest.TestLoader().loadTestsFromTestCase(TestLiblibCarAnalyzer)
    
    # è¿è¡Œæµ‹è¯•
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(test_suite)
    
    # è¾“å‡ºæµ‹è¯•ç»“æœæ‘˜è¦
    print("\n" + "=" * 60)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ‘˜è¦")
    print("=" * 60)
    print(f"è¿è¡Œæµ‹è¯•: {result.testsRun}")
    print(f"å¤±è´¥æµ‹è¯•: {len(result.failures)}")
    print(f"é”™è¯¯æµ‹è¯•: {len(result.errors)}")
    print(f"è·³è¿‡æµ‹è¯•: {len(result.skipped) if hasattr(result, 'skipped') else 0}")
    
    if result.failures:
        print("\nâŒ å¤±è´¥çš„æµ‹è¯•:")
        for test, traceback in result.failures:
            print(f"  - {test}: {traceback}")
    
    if result.errors:
        print("\nâŒ é”™è¯¯çš„æµ‹è¯•:")
        for test, traceback in result.errors:
            print(f"  - {test}: {traceback}")
    
    # è®¡ç®—æˆåŠŸç‡
    success_rate = ((result.testsRun - len(result.failures) - len(result.errors)) / result.testsRun) * 100
    print(f"\nğŸ¯ æµ‹è¯•æˆåŠŸç‡: {success_rate:.1f}%")
    
    if success_rate >= 90:
        print("ğŸ‰ æµ‹è¯•é€šè¿‡ç‡ä¼˜ç§€ï¼")
    elif success_rate >= 80:
        print("âœ… æµ‹è¯•é€šè¿‡ç‡è‰¯å¥½")
    elif success_rate >= 70:
        print("âš ï¸  æµ‹è¯•é€šè¿‡ç‡ä¸€èˆ¬ï¼Œéœ€è¦æ”¹è¿›")
    else:
        print("âŒ æµ‹è¯•é€šè¿‡ç‡è¾ƒä½ï¼Œéœ€è¦é‡ç‚¹å…³æ³¨")
    
    return result.wasSuccessful()

if __name__ == "__main__":
    # æ£€æŸ¥ä¾èµ–
    try:
        import requests
        import pandas
        import numpy
        print("âœ… æ‰€æœ‰ä¾èµ–åŒ…æ£€æŸ¥é€šè¿‡")
    except ImportError as e:
        print(f"âŒ ç¼ºå°‘ä¾èµ–åŒ…: {e}")
        print("è¯·è¿è¡Œ: pip install requests pandas numpy")
        sys.exit(1)
    
    # è¿è¡Œæµ‹è¯•
    success = run_tests()
    
    # é€€å‡ºç 
    sys.exit(0 if success else 1)
